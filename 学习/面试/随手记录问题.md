dataX是阿里系的 是一种多线程的同步数据源工具,操作起来简单方便,然后支持的数据源类型很广,我自己有在研究,里面有  里面有reader framework writer (类似fLume) 具体的就不太清楚了.   √

增量脚本多还是全量脚本多 
我是后面才进来了,据我所知一开始的什么字典表啊地域表规则表或者是那些几乎不会更变数据的表都是用的全量,而那些会更新得比较频繁的表,比如订单表啊,会员信息表我们就会每日增量的去导入,然后做成拉链表的形式放到dwd层 √


拉链表多说几个表 用户活跃  用户订单 用户会员等级  

### 星型模型 星座模型 雪花模型的区别 
星型模型:多为表的数据关系,是由一个事实表去关联多个维表组成,适合大数据的处理,缺点就是会由一定程度的数据冗余,因为会有重复的存储信息

雪花模型:多个维表没有直接连接到事实表上,而是通过其他维表去连接,就会造成一些层次现象,缺点就是会导致查询效率低下,因为会有多Join,不利于开发

星座模型:多张事实表共享维表信息,业务复杂,不经常用

### 上述三个模型的读写效率和存储空间有什么区别
1. 星座模型的读写效率较快,但是存储空间大,雪花模型较慢,但是存储空间小
2. 星座模型适合复杂的业务逻辑,不考虑读写效率和存储空间,能用就好.








### 为什么要用Kafka而不用MQ这种
1. 在消息队列这个圈子里Kafka是当下最流行的，认可度也是最高的，社区支持力度最高的
2. 高度成熟的技术和庞大的生态可以兼容当下所有的主流计算引擎，丰富成熟的API也对开发者友好



### 数仓为什么要分层
我把数仓比作一个很大的图书馆，当书本达到海量的时候，你会发现当你想要一个找到一本书的时候，查询会非常吃力，扫描全部几TB的数据，所以我们可以用空间换时间：通过建设多层次的数据模型供用户使用，避免用户直接使用操作原始数据，可以更高效的访问数据。同时可以将复杂的问题分解成单个简单的步奏来完成，比较简单和容易理解。

划清层次结构：每一个数据分层都有它的作用域，这样我们在使用表的时候能更方便地定位和理解。
数据血缘追踪：简单来讲可以这样理解，我们最终给下游是直接能使用的业务表，但是它的来源有很多，如果有一张来源表出问题了，我们希望能够快速准确地定位到问题，并清楚它的危害范围。
减少重复开发：规范数据分层，开发一些通用的中间层数据，能够减少极大的重复计算。
把复杂问题简单化。将一个复杂的任务分解成多个步骤来完成，每一层只处理单一的步骤，比较简单和容易理解。而且便于维护数据的准确性，当数据出现问题之后，可以不用修复所有的数据，只需要从有问题的步骤开始修复。
屏蔽原始数据的异常。屏蔽业务的影响，不必改一次业务就需要重新接入数据。




### 怎样保证数据质量
1.开发检验脚本，设定阈值，判断重要字段和数据条数是否在阈值范围内，判断重要字段是否为空，数据重复数量等
2.构建数据字典，注明指标含义，字段开源，开发思路
3.设置数据权限，不同数据设立不同的负责人，进行规范定位，开发维护
4.开发后交叉验证数据的正确性，一致性，完整性
5.开发前找业务表负责人整理出表的关联关系和字段含义

### 行存储和列存储的区别
（行式存储相当于套餐，即使一个人来了也给你上八菜一汤，造成浪费；列式存储相等于自助餐，按需自取，人少了也不浪费）
传统行式数据库的特性如下：
1. 没有索引的查询使用大量I/O。比如一般的数据库表都会建立索引，通过索引加快查询效率。
2. 建立索引和物化视图需要花费大量的时间和资源。
3. 面对查询需求，数据库必须被大量膨胀才能满足需求。

列式数据库的特性如下：
1. 数据即索引。
2. 只访问查询涉及的列，可以大量降低系统I/O。
3. 每一列由一个线程来处理，即查询的并发处理性能高。
4. 数据类型一致，数据特征相似，可以高效压缩。




### 
dao 层 底层逻辑
服务层处理业务逻辑
controller层


### 有1个G的文件,只有1M的运行内存,怎么处理求出出现次数前100的数据?
先遍历1G的大文件，按照Hash%1000取模将大文件映射成1000个小文件，保证了相同的词分到同一个小文件中，这样每个小文件大概1M大(也可以分多些小文件，这样每个文件大小就更小)，就可以放入内存中。在每个小文件中使用Hash_map，以单词为key，出现的次数为value，然后用最小堆得到每个小文件出现频数最多的100个单词，最后归并排序，就可以得到了