dataX是阿里系的 是一种多线程的同步数据源工具,操作起来简单方便,然后支持的数据源类型很广,我自己有在研究,里面有  里面有reader framework writer (类似fLume) 具体的就不太清楚了.   √

增量脚本多还是全量脚本多 
我是后面才进来了,据我所知一开始的什么字典表啊地域表规则表或者是那些几乎不会更变数据的表都是用的全量,而那些会更新得比较频繁的表,比如订单表啊,会员信息表我们就会每日增量的去导入,然后做成拉链表的形式放到dwd层 √


拉链表多说几个表 用户活跃  用户订单 用户会员等级  



### 怎样保证数据质量
1.开发检验脚本，设定阈值，判断重要字段和数据条数是否在阈值范围内，判断重要字段是否为空，数据重复数量等
2.构建数据字典，注明指标含义，字段开源，开发思路
3.设置数据权限，不同数据设立不同的负责人，进行规范定位，开发维护
4.开发后交叉验证数据的正确性，一致性，完整性
5.开发前找业务表负责人整理出表的关联关系和字段含义

### 行存储和列存储的区别
（行式存储相当于套餐，即使一个人来了也给你上八菜一汤，造成浪费；列式存储相等于自助餐，按需自取，人少了也不浪费）
传统行式数据库的特性如下：
1. 没有索引的查询使用大量I/O。比如一般的数据库表都会建立索引，通过索引加快查询效率。
2. 建立索引和物化视图需要花费大量的时间和资源。
3. 面对查询需求，数据库必须被大量膨胀才能满足需求。

列式数据库的特性如下：
1. 数据即索引。
2. 只访问查询涉及的列，可以大量降低系统I/O。
3. 每一列由一个线程来处理，即查询的并发处理性能高。
4. 数据类型一致，数据特征相似，可以高效压缩。




### 
dao 层 底层逻辑
服务层处理业务逻辑
controller层


### 有1个G的文件,只有1M的运行内存,怎么处理求出出现次数前100的数据?
先遍历1G的大文件，按照Hash%1000取模将大文件映射成1000个小文件，保证了相同的词分到同一个小文件中，这样每个小文件大概1M大(也可以分多些小文件，这样每个文件大小就更小)，就可以放入内存中。在每个小文件中使用Hash_map，以单词为key，出现的次数为value，然后用最小堆得到每个小文件出现频数最多的100个单词，最后归并排序，就可以得到了