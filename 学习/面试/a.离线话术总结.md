### 离线话术
那我从数据源开始说吧,您有问题可以随时打断我,因为有一段时间没做了我不是太记得.
我们的数据主要是app端,小程序端,web端埋点获取到的用户行为数据,还有业务库里的数据,第三方数据等去获得. 

1. 在采集模块上
针对主流的数据源也就是埋点获得的数据我们是用flume采集,对于另一边业务库的数据我们采用的是DataX去导入.

2. 在采集这部分我们跟前端做了个数据总线模块,目的就是为了去观察采集时的健康状态和上面的日志条数,以及会去进行判断是否去重的功能.

3. 到了数仓分层模块,我们数仓主要分为四层
ODS层主要用来保存flume采集来的数据,我们在这一层不会做任何的处理,保留最元u你是的数据去方便以后出问题时候数据溯源.

然后我们讲ODS层的数据经过一系列的预处理,包括数据清洗,过滤,脱敏,guid生成,地理位置回补这些但不等的操作后,生成一些用户明细数据表放到DWD层. 然后一些DataX导入的业务数据也会放到这.

再到DWS层,我们在这做进行了主题的划分,主体划分为房东和用户两大群体,再去自下而上的进行划分主题,根据业务需求或者业务过程的分析视角来进行划分,也就是ADS层需要什么我就做什么.比如有流量主题,民宿订单转化漏斗主题,归因主题,用户活跃主题等等

将做好的报表放到ADS层之后我们就存在doris里,方便BI的报表展示

4. 然后在外围模块上,我们是用的dolphin进行的任务调度,用的Atlas做元数据管理,对我们的表进行备注,然后理清血缘等操作.最后他们最近为了做数据治理自己做了质量管理系统,具体我不是很了解

5. 在Olap模块上,也就是我们web页面是以doris做数据库,能快速返回结果/


### ODS有多少张表,都是什么?最大的一张表有多少数据量
我负责的用户行为域 有个十多张吧 
比如有小程序访问日志表 web端的访问日志表 app访问日志表 
然后接到dataX导入过来的有 
活动规则表 活动信息表 地域表 优惠券表 会员等级表(普通白银黄金钻石)
民宿订单表 积分表  等等 

最大的一张表是app用户行为数据表,每天的数据条数会有千万,七八九月会达到亿级别


### 数仓命名 
层名-事业部-业务线-房东或者用户-主题域-自定义名字-更新周期

### 日活 月活 数据量 条数 
日活80-100万 月活300万 每天100G数据  峰值有200G



### dataX增量脚本多还是全量脚本多 
据我所知一开始的什么字典表啊地域表规则表或者是那些几乎不会更变数据的表都是用的全量
而那些会更新得比较频繁的表,比如订单表啊,会员信息表我们就会每日增量的去导入,然后做成拉链表的形式放到dwd层


### 数据服务总线   为什么开发这个服务
这个服务主要是是能给数仓提供了统计每个服务器日志的行数以及flume采集到的HDFS日志的行数,主要的功能有日志上报和日志条数查询
我们这个用到了spring boot嘛 
1. 日志的上报功能就是通过请求服务接口来传递参数,将每天的日志条数,日志类型,日期,以及服务器名等等上报到服务端,然后将数据通过Mybatis框架存储到Mysql中,且会发送邮件来提示是否已经上传成功

2. 日志的查询功能具体就是调用服务端的接口的来从Mysql中查询日志行数和HDFS的的文件行数来供后续的去重脚本使用



### 项目建设层设计到的数据调研和探索的内容大概有什么
和业务需求人员对接,数据保留的时间,数据重要的字段,统一口径字段等等


### 维度建模流程
1. 首先是以我们所要对应的业务过程来确定事实表的类型是什么，比如周期性事实表啊，事务性事实表这种
2. 然后开始精确事实表每一个字段的业务含义是什么，选择用最细粒度的字段
3. 于是围绕这个业务过程的事件发散他的描述维度信息
4. 再到确定这个过程度量是什么
5. 有需要的话将一些维度退化到事实表中
6. 再开始确定我们的命名规范，完成设计。


### 从0-1数仓建模流程
我们是自下而上的建模流程，针对客户的需求，需要什么我们做什么
1. 一开始的数据调研都是从数据源头的表,然后从web,app端的去梳理业务线逻辑
2. 然后我们会去开几个与业务部门的会议或者单独的聊天进行需求沟通，统一口径，完全梳理好业务逻辑
3. 接着对接产品经理拿到PRD文档后,我们就会开始画ER图去来明确业务的构造，确定相应的字段，明确原子指标，派生指标，衍生指标，建立中心事实表
4. 接着开始划分这个主题域,比如说什么行为域,部门域等等
5. 对这个中心事实表开始分层建模,一般都是建立ODS DWD DWS ADS 
6. 对指标进行扩散思维去拿到相应的维度，进行维度建模
7. 开始落地实表，注意一些命名规范
8. 最后进行数据校验的工作，等测试完成后续进行不断的优化操作。



###  数据量问题 业务特征 规模 用户规模  计算 (时长, 事件频次, 日志数据大小 ,用户数据)
木鸟 5000万用户  120-150万日活跃度  月活300-400万 
差不多10多秒产生一个数据 
一个人一次事件产生1.2kb
每个活跃用户平均产生70-80条数据 
每个人一天的事件大小85kb左右
每天100-200多G  
平均公司 按最大的来算就3.5M/s的数据
高峰期35M/s 
(只是暂时的 还需要更改)


### UDF的使用 
比如我们在做用那个gitee上狮子的魂做ip地理位置回补创建字典表的时候,将经纬度转成geohash值就用到了UDF
还有个人信息用AES加密算法加密、脱敏等也用到了
还有在做特殊指标的时候会用到



### 怎样保证数据质量
他们有在开发质量检测管理系统,做了一些规则管理,sql模板管理,质量度量的可视化等东西
1.开发检验脚本，设定阈值，判断重要字段和数据条数是否在阈值范围内，判断重要字段是否为空，数据重复数量等
2.构建数据字典，注明指标含义，字段开源，开发思路
3.设置数据权限，不同数据设立不同的负责人，进行规范定位，开发维护
4.开发后交叉验证数据的正确性，一致性，完整性
5.开发前找业务表负责人整理出表的关联关系和字段含义


