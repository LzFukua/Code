### 离线话术
那我从数据源开始说吧,您有问题可以随时打断我,因为有一段时间没做了我不是太记得.
我们的数据主要是app端,小程序端,web端埋点获取到的用户行为数据,还有业务库里的数据,第三方数据等去获得. 

1. 在采集模块上
针对主流的数据源也就是埋点获得的数据我们是用flume采集,对于另一边业务库的数据我们采用的是DataX去导入.

2. 在采集这部分我们跟前端做了个数据总线模块,目的就是为了去观察采集时的健康状态和上面的日志条数,以及会去进行判断是否去重的功能.

3. 到了数仓分层模块,我们数仓主要分为四层
ODS层主要用来保存flume采集来的数据,我们在这一层不会做任何的处理,保留最原始的数据去方便以后出问题时候数据溯源.

然后我们讲ODS层的数据经过一系列的预处理,包括数据清洗,过滤,脱敏,guid生成,地理位置回补这些但不等的操作后,生成一些用户明细数据表放到DWD层,为了提高数据明细层的易用性，该层会采用一些维度退化手法，将维度退化至事实表中，减少事实表和维表的关联,然后一些DataX导入的业务数据也会放到这,另外，在该层也会做一部分的数据聚合，将相同主题的数据汇集到一张表中，提高数据的可用性 .

再到DWS层,数据就会在这做轻度的聚合操作,生成一系列的中间表,我们在这做进行了主题的划分,主体划分为房东和用户两大群体,再去自下而上的进行划分主题,根据业务需求或者业务过程的分析视角来进行划分,也就是ADS层需要什么我就做什么.比如有流量主题,民宿订单转化漏斗主题,归因主题,用户活跃主题等等

将做好的报表放到ADS层之后我们就存在doris里,方便BI的报表展示

4. 然后在外围模块上,我们是用的dolphin进行的任务调度,用的Atlas做元数据管理,对我们的表进行备注,然后理清血缘等操作.最后他们最近为了做数据治理自己做了质量管理系统,具体我不是很了解

5. 在Olap模块上,也就是我们web页面是以doris做数据库,能快速返回结果

### ODS有多少张表,都是什么?最大的一张表有多少数据量
我负责的用户行为域 有个十多张吧 
比如有小程序访问日志表 web端的访问日志表 app访问日志表 
然后接到dataX导入过来的有 
活动规则表 活动信息表 地域表 优惠券表 会员等级表(普通白银黄金钻石)
民宿订单表 积分表  等等 

最大的一张表是app用户行为数据表,每天的数据条数会有千万,七八九月会达到亿级别

### 你们项目组维度表多少张，数据量大概多少。
回答20~30张左右，不能太多，可以说公司是敏捷迭代式建设数据仓库，开始只是部分核心的业务流程。

### 报表一个月大概会做多少张
40张左右

### 数仓命名 
层名-事业部-业务线-房东或者用户-主题域-自定义名字-更新周期

### 日活 月活 数据量 条数 
日活80-100万 月活300万 每天100G数据  峰值有200G

### dataX增量脚本多还是全量脚本多 
据我所知一开始的什么字典表啊地域表规则表或者是那些几乎不会更变数据的表都是用的全量
而那些会更新得比较频繁的表,比如订单表啊,会员信息表我们就会每日增量的去导入,然后做成拉链表的形式放到dwd层


### 数据服务总线   为什么开发这个服务
这个服务主要是是能给数仓提供了统计每个服务器日志的行数以及flume采集到的HDFS日志的行数,主要的功能有日志上报和日志条数查询

1. 日志的上报功能就是通过请求服务接口来传递参数,将每天的日志条数,日志类型,日期,以及服务器名等等上报到服务端,然后将数据通过Mybatis框架存储到Mysql中,且会发送邮件来提示是否已经上传成功

2. 日志的查询功能具体就是调用服务端的接口的来从Mysql中查询日志行数和HDFS的的文件行数来供后续的去重脚本使用


### 主题是怎么划分的
我们主题域就是做完业务调研的时候和业务人员一起开会讨论决定的,而且我们没办法一次划分完整主题域,都是一点点添加的.大概的先是会分为大主题的两份,一边为房东,一边为用户,然后大致会分为以业务脉络进行划分,比如订单域,门票域这种,要么就是以功能或者应用进行划分,比如大额度优惠券域这种.


### 处理过最大数据量
2020年国庆的时候处理过6亿多条的数据


### 项目建设层设计到的数据调研和探索的内容大概有什么
和业务需求人员对接,数据保留的时间,数据重要的字段,统一口径字段等等


### 维度建模流程（主要建模流程）
1. 首先是以我们所要对应的业务过程来确定事实表的类型是什么，比如周期性事实表啊，事务性事实表这种
2. 然后开始精确事实表每一个字段的业务含义是什么，选择用最细粒度的字段
3. 于是围绕这个业务过程的事件发散他的描述维度信息
4. 再到确定这个过程度量是什么
5. 有需要的话将一些维度退化到事实表中
6. 再开始确定我们的命名规范，完成设计。



### 从0-1数仓建模流程
我们是自下而上的建模流程，针对客户的需求，需要什么我们做什么
1. 一开始的数据调研都是从数据源头的表,然后从web,app端的去梳理业务线逻辑
2. 然后我们会去开几个与业务部门的会议或者单独的聊天进行需求沟通，统一口径，完全梳理好业务逻辑
3. 接着对接产品经理拿到PRD文档后,我们就会开始画ER图去来明确业务的构造，确定相应的字段，明确原子指标，派生指标，衍生指标，建立中心事实表
4. 接着开始划分这个主题域,比如说什么行为域,部门域等等
5. 对这个中心事实表开始分层建模,一般都是建立ODS DWD DWS ADS 
6. 对指标进行扩散思维去拿到相应的维度，进行维度建模
7. 开始落地实表，注意一些命名规范
8. 最后进行数据校验的工作，等测试完成后续进行不断的优化操作。


### 业务建模
那我们就需要去通过与业务部门的充分交流，来去看看我们简历这个建模真正要解决什么样的问题，然后确定各个主题下的查询分析要求。
业务建模我们按照层级一点点扩展的嘛，依次是有顶层模型，业务域，业务流程，业务环节。

1. 顶层模型，也就是从我们整体业务的角度去划分业务模块，还有各个业务模块之间的交互关系。比如公司有房东和用户的交易模块，财务模块，营销促销模块，财务模块跟营销之间的关系有营销活动发起之前要申请预算，采取需要统计营销活动的成本。交易就可以配置营销活动。
2. 业务域，是把划分的模块逐一进行分解到业务用例。比如营销活动模块可分解为，运营人员配置活动信息，用户购买产品使用优惠等等。
3. 业务流程，是将业务用例做具体的流程分解，具体到每一步操作是怎么样，以及每个环节操作之间的依赖关系。
4. 业务环节，就是他们会写SOP嘛，把一个环节的作业内容再标准化细化。


###  数据量问题 业务特征 规模 用户规模  计算 (时长, 事件频次, 日志数据大小 ,用户数据)
木鸟 5000万用户  120-150万日活跃度  月活300-400万 
差不多10多秒产生一个数据 
一个人一次事件产生1.2kb
每个活跃用户平均产生70-80条数据 
每个人一天的事件大小85kb左右
每天100-200多G  
平均公司 按最大的来算就3.5M/s的数据
高峰期35M/s 
(只是暂时的 还需要更改)


### UDF的使用 
比如我们在做用那个gitee上狮子的魂做ip地理位置回补创建字典表的时候,将经纬度转成geohash值就用到了UDF
还有个人信息用AES加密算法加密、脱敏等也用到了
还有在做特殊指标的时候会用到



### 怎样保证数据质量
他们有在开发质量检测管理系统,做了一些规则管理,sql模板管理,质量度量的可视化等东西
1. 我们有做开发检验脚本，设定阈值，判断重要字段和数据条数是否在阈值范围内，判断重要字段是否为空，数据重复数量等
2. 然后也构建数据字典，注明指标含义，字段开源，开发思路
3. 也做了设置数据权限，不同数据设立不同的负责人，进行规范定位，开发维护
4. 开发后交叉验证数据的正确性，一致性，完整性
5. 开发前找业务表负责人整理出表的关联关系和字段含义

### 数据治理
数据治理本质上就是提升数据的质量，盘活整条数据链路,然后保证公司数据一些采集计算存储的一些可追溯性吧.

数据治理在我看来是一个贯通各阶段的长期工程，数仓建设初期，更多的体现在技术规范和统一口径上，确保数据的质量；数仓迭代阶段，这时更应该注重架构治理，明确数仓分层，主题边界，消除数据冗余，提升数据一致性；资源治理，针对不同层级数据采用不同生命周期管理策略；安全治理，制定数据安全规范，统一各业务线的数据权限管控标准；数仓稳定阶段，建设数据治理平台更高质量的执行制定的一系列规范。

然后就做了数据质量管理、元数据管理、主数据管理、数据资产管理、数据安全及数据标准等内容。


### 为什么你们Hive底层用的是mr 不是用的spark
hive基于mr更稳定，spark不是很稳定嘛容易OOM。而且我们是做t+1的，hive开发成本就比较低

### 你们是怎么做数据校验的，就比如说你们业务部门觉得计算出来的和他所设想的有问题你们怎么解决的
就是ADS的报表和mysqL的结果比对一下
或者是做交叉验证，在不同的表里面进行比对

或者就是抽取生产环境的2000条数据然后运算核实一下
测试完之后打包脚本 然后跟总监和运维说一下,运维负责上线.