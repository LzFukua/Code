### Kafka在Zookeeper中存储的元信息有哪些？
1. broker相关信息
2. 控制器在哪台broker的信息
3. 所有消费者的信息
4. 集群管理信息 (比如partition重分配,最优选举leader的副本,近期删除的topic)
5. ISR变更信息


### Zookeeper在Kafka的作用
1. 记录Topic和Brokers的元信息
2. 负责生产者和消费者的的负载均衡,动态的感知到Broker的信息变更
3. 消费进度记录
4. 选举leader


### kafka怎么保证数据不丢失(容错性)
如果说到kafka深层原理的话,kafka是不能保证数据完全不丢失的
在Producer端丢失数据
1. 在生产者的方面 由于有应答机制,如果不是-1的情况下就会有可能丢失数据   
2. 在broker方面来看 刷盘时如果突然宕机,选举了一个落后了很多的当选成Leader也会丢失数据
3. 在消费者的方面 由于数据默认为自动提交偏移量,或者是半自动的提交偏移量 所以就会有数据丢失的现象,认为你已经消费过了
   
所以策略为
生产者端
1. 设置callback函数来使得生产者发完数据后会回调通知
2. ACKS设置为-1
消费者端
1. 采用手动同步或者异步提交偏移量（同步会堵塞线程进行失败重试，异步有可能会提交失败）


### kafka乱序
1. 如果不是单节点，没办法做到全局有序,单节点解决乱序的方法就是把指定的key放到同一个分区里,然后用一个消费者专门消费它,就可以保证这条节点的顺序了.
2. 如果非要多节点解决,我认为那就搞几个内存队列,然后让相同key的都到同一个内存队列里,让几条线程对应的去消费.
3. 但是这样发生了消费组的重平衡的话,就解决不了那种没消费的信息被打乱的问题.


### kafka保证数据不重复
1. 生产端开启幂等性
2. 可开启事务或者是手动提交偏移量,利用mysql/redis的事务来达到去重目的



### kafka怎么实现高吞吐低延迟
1. 顺序读写
2. 零拷贝（跳过用户缓冲区拷贝，直接映射磁盘空间和内存）
3. 批量发送 生产者缓存本地，等条件触发了才发送到broker
4. 数据压缩
5. 分区


### kafka有哪些特点
1. 高吞吐量 低延迟(因为是顺序读写且零拷贝机制)
2. 可扩展
3. 容错性
4. 高并发 

### 为什么要使用kafka 
1. 给上游数据的缓冲与削峰的作用
2. 而且作为流式数据的消息中间件他应该是市面上的首选

### kafka分区的目的?
实现负载均衡 提高kakfa的并行度


### kakfa数据怎么保证的一致性 
首先kafka做了一个 HW,是AR最小的LEO,用来保证读的时候所有副本消费出来的数据都是一样的,但问题在于,副本知道水位线的时候总是漏一拍才能知道水位线在哪,这是和宕机了leader更换就会导致数据丢失,而0.11版本之后添加了一个叫leader-epoch机制,因为他会记录每个leader偏移量,然后再去让follower从他这个朝代的偏移量开始以前的截断数据且只记录当朝的.



### Kafka CAP保证(分布式理论才有CAP)
Kafka舍弃了分区容错性
C一致性
A可用性
P分区容错性 


1. kafka首先将数据写入到不同的分区里面去，每个分区又可能有好多个副本，数据首先写入到leader分区里面去，读写的操作都是与leader分区进行通信，保证了数据的一致性原则。
2. 然后kafka通过分区副本机制，来保证了kafka当中数据的可用性。可以做正常的读写操作
3. 但是也存在的问题是副本和leader的数据有差别的问题



### Kafka分区分配策略
range 分配: 每个topic除以2 然后平分  这会导致前面的那个永远是多的
round分配 : hashCode打乱之后轮询方式分配
Sticky分配 尽量保留之前分配好的分区 不会去重新打乱 但是还是会取消所有再分配
Cooperative分配  这个就会一个个取消 消费者不用取消所有分区,只需要反馈自己的分区信息,然后Cooperative就会去找zookeeper获取元数据来得到本组订阅的主题有哪些分区,然后根据策略算法去让某分区停止获取,然后再去发送再均衡通知,再让新加的消费者去负责该分区    



### kafka为什么要设立水位线
Kafka为了不让消费者在消费的时候会读出不同的结果
(因为在读leader的时候有可能会挂掉,就会让没有同步的follower在leader挂掉的那一刻然后它变成了leader的时候,消费者读到的数据不一致)
所以设置了高水位线,让所有消费者只能读到每个broker 偏移量比水位线更小的数据
所以总结为 高水位线HW解决了消费者所见不一致的问题
          leader-epoch解决了副本数据最终一致性的问题


### kafka的分区数只能增加 不能减少
本身kafka就是不支持减少分区的，因为减少分区会使得这个分区的数据不知道该去哪里，删除了就丢失，放到别的分区就会破坏单分区的有序性。


### kafka的传输语义(acks)有几种
1. **acks** = 0      意味着如果生产者发送了出去就代表已经成功写入topic 
2. **acks** = 1      意味着leader收到消息且返回应答就代表已经写入到topic
3. **acks** = -1/all 意味着所有ISR都要返回应答才会认为写入到topic

### kafka的存储结构(消息格式)
1. 物理上的存储结构是,有索引文件,时间索引文件,数据存储以及leader纪元文件
2. 消息存储格式是,校验内容crc,kafka版本magic,key value 以及他们的长度,还有一个压缩类型attributes

### kafka 创建Topic时候是如何将分区分配给Brokers的
第一个分区的第一个副本是随机发放到某台broker上,接着轮询往给后存放副本


### kafka消费者和消费者组的关系
我的理解是一群消费者起一个团队名就叫消费者组了
kakfa就要保证一个partition在一个消费者组内只能被一个消费者消费,但不同组内同一个分区可以被多个消费者消费
还有就是每个消费者组一定会完整的消费一个Topic下所有分区

### 谈谈kakfa消费者组的分区再均衡机制
1. 触发再均衡机制一般有 组内成员发生变动 还有 分区增加/topic发生了变动 就会产生再均衡机制
2. 而再均衡有四种策略
   1. range策略 也就是topic分区数除以消费者数得到 的每个消费者该得到多少分区 且前面的组员会多得一些
   2. round策略 按轮询的方式获得分区 但有可能会乱序
   3. Sticky策略 去尽可能的保留原来消费者所负责的分区再去均衡
   4. Cooperative策略  完善了不会去将所有的分区取消再去均衡的策略,而是去拆解为多次小均衡来达到全局均衡


### kafka幂等性实现原理
1. 每一个生产者初始化会生成一个producer_id,并给每个目标分区维护一个"消息序列号"
2. 生产者每发送一条消息,就会将     <<producer_id,分区>>    的producer_id +1 
3. 然后每发送一条消息都和前一个进行对比
   * 如果 old == new -1  正常 5 = 6-1
   * 如果 old >  new -1  例如 原来存的是6  发过来的是 6号数据 及 6 > 6-1  说明重复写入 直接丢弃数据 
   * 如果 old <  new -1  例如 原来存的是6  发过来的是 8号数据 及 6 < 8-1  说明数据丢失/发生乱序 抛出异常 


### kafka事务 
kafka事务是一个伪事务
只支持不断追加 所以并不能真正的把未提交的事务结果进行物理回滚 而是让消费者只看到开启事务的那片数据
理论为 从打事务标记的开始到事务结束的标记 让消费者开启只能看到事务提交的数据 这样就能逻辑上展现事务


### kafka的监控你们用什么
EFAK

### kafka控制器Controller的作用
1. 管理broker的上下线
2. 所有topic的分区副本分配
3. leader选举

### 名词解释 ISR OSR AR LEO HW LSO LW
ISR:副本同步队列
OSR:没跟上leader暂时被踢出的副本
AR :所有副本
LEO:日志文件中的下一个偏移量
HW :高水位 指的是AR最小的LEO
LSO:是指事务的第一条消息 如果没开启事务就没意义

### kafka生产者的数据发送流程 (写流程)
1. 连接到 zk 集群，从 zookeeper 中拿到对应的 topic 的 partition 信息和 partition 的 leader 的相关信息
2. 连接到对应的 leader 对应的 broker
3. 生产者将信息写给leader 
4. leader 将消息写入本地 log， follower 从 leader pull 同步消息
5. 同步完后依次向 leader 返回/发送 ack


### kafka消费者读数据的流程(读流程)
1. 连接到 zk 集群，从zookeeper 中拿到对应的 topic 的 partition 信息和 partition 的 leader 的相关信息
2. 连接到对应的 leader 对应的 broker
3. consumer 将自己保存的 offset 发送给 leader
4. leader 根据 offset和epoch信息定位到索引文件和日志文件（索引文件 .index 和日志文件 .log ）
5. 根据索引文件中的内容，二分查找定位到日志文件中该偏移量对应的开始位置读取数据并返回给 consumer


### Kafka 消费者角度考虑是拉取数据还是推送数据
从消费者角度考虑的话是拉取数据,因为如果是被推送数据的情况下,推送速率要大于消费者消费速率,那么消费者就因为肚子撑太多排不出来而挂掉
而pull模式下可以根据消费者的能力去拉取数据,只是pull模式下会导致一直轮询的去问是否有新数据,但可以设置参数让消费者处于堵塞状态直到有新数据出现



### Kafka高可靠性
多分区副本,动态分区leader选取,ack机制



### kafka如果数据积压了,消费能力不足怎么办
1. 如果是消费能力不足,那就增加topic的分区,提升消费者的数量
2. 再不济就关闭一些不重要的业务
3. 或者是去找监控消费端或者是日志,看看是不是线程的问题


### Kafka分区的参数
分区设置
副本设置
线程数设置
服务端口设置
日志留存时间设置
zookeeper配置
空间留存策略设置
周期性检查设置
