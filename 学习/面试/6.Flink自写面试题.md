
### Flink的四大基石
1. Checkpoint重启策略  Checkpoint 本质就是对状态的备份, 持久化到文件系统
JobManagerCheckpointStorage  FileSystemCheckpointStorage
2. 状态 用来保存中间计算结果或者缓存数据
旧版 
MemoryStateBackend  基于内存存储
FsStateBackend  基于文件存储
RocksDBStateBackend  基于RocksDB数据库存储 
新版
状态后端有两种存储 (底层的具体实现)
HashMapStateBackend  存什么就是什么类型的 
RocksDbStateBackend  以序列化的形式存储在rocksDB数据库中 
主要在于效率问题 hashMapStateBackend快  因为放在内存中 多出来的溢出在磁盘
弊端为内存空间有限,所以在磁盘的会慢 所以数据量不算大的时候用这个
3. Time 时间语义 

4. Window 将无限的数据流划分成多个有限数据流的手段 希望将数据攒起来做微批次的处理 
事件时间的度量标志为水平线, 事件时间应用于窗口中


### watermark的意义
1. 标识Flink任务的事件时间进度，从而推动事件时间窗口的触发和计算
2. 解决事件时间窗口的乱序问题
flink1.11中对flink的水位线生成接口进行了重构，创建watermark主要有以下三种方式
1）使用createWatermarkGenerator 创建watermark。
2）使用固定延时策略生成水位线，调用WatermarkStrategy中的静态方法forBoundedOutOfOrderness。
3）使用单调递增的方式生成水位线，调用WatermarkStrategy中的静态方法forMonotonousTimestamps

### Flink时间语义
Flink在1.12版本后默认使用Event Time
1. 处理时间（Process Time）系统时间
2. 事件时间（Event Time）数据源提供的时间
3. 注入时间（Ingestion Time）数据进入flink的时间


### 如何保证数据不丢失
Flink不能保证数据不会丢失，最多只能通过设置较大的延迟时间来让乱序的事件到达。


### Flink保证Exactly Once语义
举例kafka保证Exactly Once
1. source阶段 把kafka消费者的消费位移记录在算子状态中
2. sink阶段
   1. 采用幂等写入方式
   2. 采用两阶段提交事务写入方式
   3. 采用预写日志2PC提交方式



### Flink容错机制
重启策略+状态
一个为checkpoint，一个为savepoint，checkpoint默认为自动保存到状态后端。

### flink checkpoint的原理 以及怎么实现的
Flink分布式快照算法,异步 barrier 快照


### 检查点分界线 barrrier  分布式快照算法
形象化的来说，jobmanager会给每个任务做完的时候插上木板拦截下来让他分身拍照，另一份数据会继续往下流。
通过插入序列号单调递增的barrier，
把无界数据流划分成逻辑上的数据段，
并通过段落标记来为这段数据的处理加持事务的特性，
就有了每一段数据流要么全部一次处理成功，要么回滚一切不完整的任务。
### 检查点原理描述
jobmanager内部有一个checkpoint协调器,触发之后向TaskManager中的subtask发送RPC消息,让subtask中持有的状态保存到HDFS中或者别的地方(StateBackEnd 保存状态的存储后端),(存储的文件记录了元信息),然后所有TaskManager返回通知给jobmanager,此次checkpoint才算已经完成,如果中途有个出现异常,jobmanager会将此次checkpoint全部取消



### Flink八大分区策略
1. GlobalPartitioner 该分区策略将上游的分发到下游算子的第一个实例中
2. forwordPartitioner 该分区策略用于在同一个operatorChain(算子链)中进行转发,上下游并行度需要一样
3. shuffle partitionner 该分区策略会将元素进行随机分区
4. rebalance partitioner 该分区策略以轮询的方式去为元素分区
5. rescale partitionner 该分区策略会根据上下游的Task数量进行分区,根据节点轮询
6. broadcast partitioner 该分区策略会广播给所有分区,每个节点各有一份复制在自己手里
7. keyGroupSteam Partitioner 该分区策略根据keyGroup的hash进行分区
8. 用户自定义分区 需要用户实现partition接口来实现自己的逻辑


### Flink提交模式
session模式 多个job共享同一个集群，job退出了集群不会退出
（大量小job的时候比较适合，因为不用频繁向yarn注册应用）
提交job先启集群 再提job


perjob模式 每个job独享一个集群 job退出集群也退出 main方法在服务端上运行
（大job运行时长很长的时候比较适合）
提交job的命令即是集群的又是job的

application模式 生产用得多 每个Job独享一个集群， job退出集群也退出 main方法在集群上运行
提交job的命令即是集群的又是job的（底层会使得main在集群上启动）


### Flink提交作业的流程
1. 提交 App 之前， 先上传 Flink 的 Jar 包和配置到 HDFS， 以便
JobManager 和 TaskManager 共享 HDFS 的数据。
2. 客户端向 ResourceManager 提交 Job， ResouceManager 接到请
求后， 先分配好容器， 然后通知 NodeManager 启动
ApplicationMaster。
3. ApplicationMaster 会加载 HDFS 的配置， 启动对应的
JobManager， 然后 JobManager 会分析当前的作业图， 将它转化成执行图
，从而知道当前需要的具体资源。
4.  接着， JobManager 会向 ResourceManager 申请资源，ResouceManager 接到请求后， 继续分配 container 资源， 然后通知ApplictaionMaster 启动更多的 TaskManager。
5. TaskManager 启动后，会向 JobManager 发送心跳。JobManager 向 TaskManager 分配任务。


### 你们公司Flink用什么监控的 
普罗米修斯+Grafana顾罗方娜  检测Flink的度量Mertic 
有时候也会去flinkweb端页面去看


### 1 小时的滚动窗口,一小时处理一次的压力比较大,想让他5分钟处理一次.怎么办?
自定义触发器，重写4个方法



### window 后面跟 aggregate 和 process 的两个窗口计算的区别是什么？
1. aggregate： 是增量聚合， 来一条数据计算完了存储在累加器中，
不需要等到窗口触发时计算；
2. process： 全量函数， 缓存全部窗口内的数据， 满足窗口触发条件
再触发计算， 同时还提供定时触发， 窗口信息等上下文信息；
3. 应用场景： aggregate 一个一个处理的聚合结果向后传递一般来
说都是有信息损失的， 而 process 则可以更加定制化的处理。



### Flink旁路缓存 
也就是所有请求优先访问Redis缓存，若缓存命中，直接获得数据返回给请求者。如果未命中则查询Hbase数据库，获取结果后，将其返回并写入缓存以备后续请求使用。


### Flink反压 