### 项目介绍
我们战略之眼这个项目严格意义上的来说是是一个事件驱动型的应用，不属于通常的数据统计开发，是一个业务导向的系统，主要的功能为我们的业务人员在web端经过画像标签特征圈选好所指定的人群，然后通过采集在线用户的行为，然后对这些人群进行规则匹配,然后触发一些营销手段。
举个例子，比如对消费能力等级在3以上，并且在最近5天内有过收藏重庆民宿十次且分享次数达到三次，当她再次搜索重庆民宿的时候，就立即给她推送一个299-20的活动券通知，从而促成她的下单消费；

那么亮点也就是我们做到了任意规则的计算模型+同一种模型参数可以任意变相结合.

1. 架构想象为一张图，上半部分为数据静态接入模块，而上半部分左边为从kakfa那边实时采集用户行为日志后经过预处理得到的用户明细数据，存入到Doris中，那kafka还有一条分支是流向Flink的，后面再说。右边为离线数仓组所提供的用户画像，以ElasticSearch存储，从ES圈选的人群就会把用户的guid我们做成bitmap，而且每天都会定期更新。到这里，Doris的作用是什么呢,Doris的作用就是里面存放着一些历史数据做为规则条件的初始值，也就是Doris的数据放入到redis集群中作为Flink的状态他就变成了我下面要说的运算机的初始值，就比如我今天发布规则，而我圈选的日期是横跨了历史和未来的，那么所用到的历史数据就从Doris来,然后再进行计算模块的累计和判断。
2. 中间部分为规则注入管理模块
那运营人员会在web端选择人群以及制定规则嘛，发送过来的json串，我们解析完之后做好规则模板以groovy脚本去注入的嘛，以enjoy模板代码来动态解析更改，然后写好的代码一起存到Mysql元数据库里，而后续的增添规则或者维护工作，我们只需要去修改Mysql元数据库就能实现。
3. 下半部分为规则计算引擎模块，也就是从Mysql的这张规则模板表用Flink-CDC监控然后广播出来，然后和Flink接kafka的实时数据进行连接,将这条行为信息进到每个规则运算机去判断是否符合条件，符合条件的就将运算结果输出出去，而不符合就让Redis状态数据进行变化，比如说用户今日浏览上海民宿1次,没能达到规则要求,那么redis的状态就给他+1.一直到该用户规则满足后再触发。
项目的大体就是这样。

我是跟着组内去负责这个规则平台的后端引擎这块部分


### 具体做了哪些
就拿行动次数举例子吧
我们的规则因为肯定会有不同的条件组合然后可以做到且 或 与 非等等关系，那前端发布完规则之后会生成json串,而这个json串是我们和前端开会好讨论决定的,他发过来之后我们这边就分为几个大的模块,

第一个就是我们的人群圈选,我们的一个标签条件,我们就利用了ES的api,比如说什么rangeQueryBuilder,去匹配什么某个标签等于多少,某个标签大于多少这种。那么查询出来的结果我们把他先保存到一个对象存在list里面，然后遍历封装成Roaringbitmap。

那么就来到了那个doris的部分,规则模板引擎怎么做的，我们这里有个规则模板元数据表,我们的规则模型,规则ID,还有一些什么sql模板,那我就会拿这些去渲染,那渲染是一个什么样的过程呢，我拿到这个json串解析完之后,有一些什么规则条件,比如说点击什么页面多少次这种,由于我们会有多个规则条件嘛就我刚刚说的且或与范围等等,那我的sql就是得要去用select count去统计次数嘛,然后就是一些过滤条件where不同的事件嘛以及我们规定的范围,可以是and也可以是or,规则和条件都是不定的,那这个时候我们不可能每个规则都要搞一个sql然后去取,这样会有大量重复开发的操作,所以不如动态的去更改,那么就得需要动态模板引擎嘛,那我们就用到JFinal里面的enjoy的轻量级模板去做,那这个模板就很简单了就什么一些for end if什么的 循环去把对象的东西动态的取到。

那现在sql就已经生成好了,那就是用这个sql对Doris进行查询，得到的结果就可以存到redis里面。

那我这边还有个groovy模板代码表,它这个也是用enjoy模板去动态写的,因为代码我们这里有写好的isMatch的匹配方法嘛，也就是然后看用户行为明细里的事件次数条件,看用户在redis的实际值是不是满足了我们设定好的阈值，如果没有满足就进到calc方法,就是去让redis里面的数据进行变化的，也就是我之前说的来一条还没达到阈值就改变redis里面的值，就这个代码取出来enjoy渲染一下。

(触发事件通过去用户行为封装好的对象去判断该事件是否是触发条件,是的话才走isMatch匹配方法)

现在我手上就有了json串，sql模板，groovy模板，然后我们就把这些东西一起注入到元数据表里面。

那现在说的这个规则引擎的部分
那我们就用flinkcdc去监控mysql的这张表嘛,如果你这条规则上线了,我们就监控到你的stage字段的状态变化,我们就把这条记录全都取出来,我们做了一个rulemetaBean这么一个对象,存进去之后呢我就能拿到你的模板代码,就类似于java里面的类加载器嘛,相当于已经动态加载到flink里面了嘛,就是可以来一条行为日志就调用一下我们设定好的processElement方法，也就是来一条信息我们就遍历每个规则。

### groovy代码哪来的啊
我们是提前维护了一张表，然后(JDBC)抽取出来渲染出来再放到元数据库表里面
sql模板也维护了一张表。


### 为什么不用Flink CEP
一开始的时候，我也感觉这个需求跟flink cep的适应场景很匹配，可是后来跟老大那边详细沟通了一下后，发现他们有一个非常关键的需求点就是： 要求能够在job不停的情况下，在线动态地改变运营规则，比如可以发布新规则，下线已运行规则，或者重新上线已经停用的规则，修改已运行中的规则的参数等等，而且都要求能够实时生效；

所以如果用flink cep的话，一旦把规则写好，就定死了，如果需要动态增加或者修改规则，必须新开发job，或者修改原来的代码，然后把原job下线再上线新的job，无法满足营销人员的快速灵活营销需求；

所以我们是自己设计了一套机制和逻辑，来实现这个系统；用到的技术栈主要就是flink的cdc、广播、processFunction，另外还有用于注入动态逻辑的groovy，还有就是用于查询行为明细的doris库和查询画像属性的ES；

### 为什么用Bitmap
因为人群量庞大嘛,如果用list或者其他的数据结构，那都要塞到爆满了,用bitmap就可以这个人符合了这个画像就在bitmap的位置勾个1就好，简单轻量。

而且我经过测试，一个达到1亿级别的数据的bitmap，体积大约12M
放入mysql完全没问题（选择字段类型为：至少是mediumblob，保险起见干脆选择longblob（4g））

### 为什么要用ES而不用Hbase
那我们用ES是因为他可以做到模糊查询，而且它支持的查询功能是比较丰富的，做一些词汇的复杂查询是完爆Hbase，就比如可以做到match的语句模糊查询，indices权重比查询，还有一些什么位置信息五公里内的查询，还有就是ES他自成一个体系的嘛，维护起来就稍微好一些。

### 为什么要用doris 
1. doris维护成本更低一些,不需要太大的集群规模,运维也简单,社区
2. doris上手也比较简单一些,sql都是标准化的,然后我们暂时也不需要那么多的函数 

### 为什么不直接查询doris而是用flink遍历规则运算机
我们每秒处理的数据量几万，如果查Doris并发太高，延迟也会变高，同时Doris集群数量也会变多，实效性和成本都不好控制
你就说flink本身是计算引擎，为了保证我们满足我们的qps，保证没有延迟，我们必须这样配置



### 为什么要用redis
1. redis对外开放，需要对运算结果或初始值等进行人为干预的话，很方便
2. redis中有丰富的数据结构，因为中间聚合结果的数据结构会有差别,我们要拿这个状态与未来在线运算的相结合嘛,这也会为我们的滚动增量运算逻辑设计带来潜在的帮助
3. redis本身的读写速度与flink内部的state不相上下，可以满足我们的高并发低延迟读写要求,也仅仅只是丢失一丢丢checkpoint回滚的特性,但我们不用去计较这种错误,最多造成的也只是他获得了一个我不该发的优惠券而已,没必要去为了精度丢失掉时效性就或者性能


### 关于redis中的数据容量的问题
redis中，一个hash结构中的kv条数最多就是整数最大值嘛，而我们的一个规则的一个条件状态记录hash中
，也就30万人左右（30万个元素），很轻松；

站在整体来看，比如上线了50个规则，每个规则平均4个条件，那就有200个条件，那就是200个hash，也是很轻松的；

而且，如果redis负载能力不够的时候，可以部署redis集群的；比如5台机器；那么200个hash就可以分布到5台机器上，相当于每台机器只要负载40个hash结构即可！很轻松！



### Groovy是什么
groovy是一种动态脚本语言,在动态编译加载的时候比java更加的简单,反射后得到对象就能直接调用计算方法得到数据,在我们这个项目就是用来做不同规则模型的导入，不然用java代码写的话一写就把代码写死了，需要把任务停了才可以重新创造类。

### redis 标签存储格式
规则序号：条件序号 --> （guid,次数）


### 你们的qps多大?
您是说app嘛，我们公司日活120万左右,峰值时候同时在线人数4万,qps为1.2w左右。
flink配置了12台服务器

### 日活 月活 数据量 条数 
80-150万  300-400万  120G数据   


### 为什么要用Kafka而不用MQ这种
1. 在消息队列这个圈子里Kafka是当下最流行的，认可度也是最高的，社区支持力度最高的
2. 高度成熟的技术和庞大的生态可以兼容当下所有的主流计算引擎，丰富成熟的API也对开发者友好
3. 而且我们强调的是时效性的问题，不是有序性，所以快才是关键


### 规则sql模板存在mysql的字段
1. 规则模型id
2. 条件类型 大于小于
3. sql模板 text
4. 作者
5. 审核人
6. 创建时间
7. 修改时间

### 规则引擎资源字段
1. 模板id
2. 规则id
3. bitmap
4. json
5. groovy代码
6. 状态上下线 

### 从kafka到flink规则计算引擎，如果有5个分区，怎么保证数据从5个分区取得的数据是有序的
因为我们上游数据采集系统在写数据到kafka的时候,用了自定义分区器,就把相同用户的数据写到了相同的分区,这样下游消费的时候,同一个用户的数据就不会乱序了


### 重点之一 动态Keyby
我们的规则需求中，一开始我们运营人员所指定的规则，在计算的时候基本上都是按照用户为单位进行计算对吧，所以，我们的整个处理逻辑中，是把数据先keyby（用户id）后，再进行核心逻辑的计算的；  但是后来，需求那边偶尔也会提一些“风控类”的规则，比如“同一个ip地址在指定时间跨度内，出现过N次登录密码错误”等规则，那这些规则对匹配计算的逻辑上，需要按照ip字段来进行keyby

所以，如果代码中把keyby写死，则无法适应上面所说的这些需求了；

那这个时候,我们就设计了一个动态keyby的方案；
简单来说，就是首先我们要在注入的规则参数中，先要按照我们的规范指明：这种规则的匹配计算它需要按照数据中的哪个字段进行keyby
然后，在我们的数据处理逻辑中，我们会先把数据按照各个规则中的keyby要求，提取出所需要的所有“keyby”类型，比如（有按设备id的，还有按ip的），那么，我们就利用反射手段，从数据中提取出指定的这两个字段的值，然后把一条数据“复制”成两条，分别带上deviceid的值和ip的值，并命名为“keyByField”字段，后续在keyBy时，就写 keyBy(bean->bean.keyByField)就ok了.


### 你们用的什么什么时间语义？万一有数据延迟到达怎么办？
我们的这个项目强调的是**时效性**，而不是数据统计的**完备性**,
如果用时间事件语义，那么当数据迟到时，可能会导致我们整个时间推进延后！不符合我们的时效性要求！
我们在这个场景中，采用的是process time时间语义，而且，我们的程序并不是用window算子等来实现的；而是处理逻辑完全由我们自主控制的，我们可以在规则运算机中根据需求，判断当前的系统时间以及到达的事件的行为时间，是否满足我们的要求做出不同的处理！

### 数据重复消费问题你们怎么处理 
重复消费的这个问题,那就证明了在收集过程中产生了故障,那故障的问题也并不是每次都产生了重复对吧,还会产生其他的问题,那就是排查bug的问题了,如果您说的是精准一次的问题,那我们并不会去处理这个,因为这个重复并不是一直在产生的,产生的后果也就是发了个不该发的优惠券而已,我们本身就是希望他消费,所以没那么大的关系.


###  发布规则之前会查询动态画像条件历史值并发布到状态，然后规则再上线运行，这中间有一点时间差，那么，是不是会产生计算的遗漏？
哇这个问题好牛。
这个问题确实存在！
只是，在咱们这个智能运营的场景中，能够容忍一定程度的不精确；
另外，这种漏算数据的概率其实也很小，第一，时间差很小；通常在10s以内；第二，在这段时间差内，用户的行为数据中也不一定就包含规则条件中所需要的事件；

当然可以，我们在下一个版本的迭代计划中，已经设计了相应的方案，而且在测试环境中已经经过了测试；
方案是这样的；
1. 我们添加了一个功能，也就是能够一次性接收一批用户行为事件进行处理,用ListState去获取,并且这个TTL设置为30s,也就是说假设我10点55秒的时候这规则上线了,那我状态里的数据就是25-55秒的,我这一批都给规则运算机去,然后它自身就会判断应该要从什么时候开始截断,也就是说doris查询历史值的一瞬间是10点50秒的话,那sql语句查询窗口的end也就替换成50秒,它从元数据库发送到redis的时候,我们也就顺便查一下这个截止时间点,然后再去取到状态里的数据,这批25-55秒的数据,我们只要50-55秒的.
2. 具体的做法也就是在flink引擎中，添加一个机制
来一条用户行为事件,我们就遍历每一个运算机,因为运算机会有一直在跑的嘛,会有多条规则一直在上线着,那就判断这个运算机是不是第一次运行的,如果是的话,就把这个存储了30s的状态丢给运算机去批处理,批处理完之后,再把新来的这条用户行为事件去让他正常处理,如果不是第一次运行的状态机,是之前一直在跑的,那就让他正常处理.


### 这个项目怎么做成实时画像
ES改成Hbase或者Clickhouse,然后规则运算机就直接去查询数据库,接着改变数据库里面的数值,但要要求配置够好集群规模够大才可以实现吧,这样就可以动态的去查,就不需要像我这个项目的做人群圈选了.


### 这个项目我们为了让用户数据有序用了kafka自定义分区,那自定义分区对什么进行分,如果用guid的话那预处理过程的guid怎么搞定..
我们这个项目不做guid了,因为我们在离线数仓那边发现,需要去更改guid的人很少很少,所以我们决定用设备id来决定分区(用guid还会使得整套流程变慢,会很麻烦),这样也能保证有序性

### kafka自定义分区之后和flink对应的并行度一致,那flink还用不用keyby
如果仅仅是要去决定是否有序的情况下,我们是可以不需要对他进行keyby的,但我们必须要keyby的原因是,我们的状态是keyedstate,存入state的数据是一定要一个人对应一个数的,所以是必须要keyby来发配的

### 这个项目整套流程会不会产生数据倾斜的问题
这项目是会有数据倾斜的问题的,我们实测会发现,晚上8点到8点半的时候,会有一部分的Task涌入量会比其他的大很多,但我们做了富裕配置就是用来解决这个的,听说比超出峰值还要多一点,而且这个倾斜量也只是一段时间内的,就比如这个task在这个半小时内会大量数据,但下一个时刻他数据就会变小、


### 规则2 行为序列
我们的sql就写的是在范围时间内去取这个人的所做的行为与我们设定规则相等的事件ID，然后就可以在doris查询时候进行时间排序，然后去匹配规则，然后就可以做到，这个人他目前做这一套链路流程他已经完成几次，并且他最后到了哪步了。然后把到达的步骤和完成的次数就放到redis里面，那就到了规则运算机那边，用isMatch方法去匹配看他是不是已经到达了所要完成的链路次数和是否到达了最后一步。calc方法也会去计算他如果是否已经完成了，没完成就+1.完成了就重置步骤号为0。

（如果需要两者结合，我们把他设定为一套新的规则，而不是拆开来匹配。）

### 规则3 下单未支付15分钟
我们有一个新的规则定义需求：判断一个人在做了A事件后，15分钟没有做B事件，则输出触达信息！（促支付）

规则运算机中，需要针对需求，写上注册、删除定时器的逻辑；而且还要增加一个定时器触发时的工作逻辑代码timer()；

flink引擎中，对于正常的事件处理，跟普通规则一样，传入userEvent给这种运算机，运算机拿到userEvent进行判断，该注册定时器就注册定时器，该删除就删除；
然后，当定时器成功触发时，flink的ontimer方法中，就取出该触发时间上注册的规则，调用规则运算机的timer()方法，进行处理即可；




### 规则
1. 单事件次数条件类
2. 单事件统计属性类
3. 多事件序列类条件
4. 多事件间隔类
5. 多时间属性统计比较类




### 如果，根据一条用户行为，往redis中进行了聚合状态的更新（比如某个值加了1），然后突然flink发生了故障，重启后重新消费用户行为，那么，有可能会把前面消费过的那条数据重新消费一次，然后导致往redis中的聚合状态重复更新了一次（比如重复多加了一次1），这个问题怎么解决？
我们还处于一个不完善版本的运行状态，先达到一个数据流程跑通大效果，然后您说的这个问题，其实我们也有考虑到，目前筹划在接下来进行迭代完善，组里面现在有两个思路，一个是把redis组件替换成用flink自身状态来做，这样能保证故障重启后的状态一致性问题；但这样就失去了使用redis的便利性；也略微增加了flink状态管理的压力；  
另一个思路是继续用redis，然后在我们自己的逻辑中对增加一些逻辑来改善一致性的问题；比如在写redis的流程中通过增加一些标记状态来判断故障重启后是否需要更新redis