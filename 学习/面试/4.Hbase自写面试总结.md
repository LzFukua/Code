### 说一下HBase的架构吧
1. HMaster负责region的负载均衡,迁移恢复region，数据库DDL操作(创表,删表),以及元数据的变更
2. HRegionServer负责管理Region的DML操作(select insert )
3. Zookeeper负责记录meta表元数据信息和regionserver的心跳信息
---

### Hbase的核心概念
1. region:表的行数据范围 将一张大表划分为多个region,将region交给不同的RegionServer管理构成分布式数据库
2. region里有
   1. store:一个列族有一个store
   2. memoryStore:内存
   3. WAL : 恢复日志
   4. storeFile:内存flush到HDFS形成的file文件的映射
   5. blockcache:缓存 提高查询的效率

---

### MemStore的作用
1. 存储在HDFS上的数据需要按照rowkey排序,而HDFS设计的是顺序读写,所以设计memstore是为了在存入HDFS之前完成排序
2. 可作为一个内存级的缓存,新插入的数据比老数据更频繁的使用
3. 批量导入磁盘,提高写的性能

---

### HBased的特点
1. 大:可以存很多很多的数据
2. 列式存储
3. 稀疏:对于空的列不占用资源所以会有稀疏性
4. 数据多版本
5. 数据类型单一:Hbase的数据都是字符串

---
### HBase的RowKey设置原则
1. RowKey的长度原则:长度一般不要超过16字节
   1. 数据是以KV形式存储,过长了如果数据过多那就会影响存储效率
   2. memStore会缓存数据在内存,过长也会使得内存有效利用率降低
2. RowKey散列原则   
   主要是散开就不会触发热点问题
3. RowKey的唯一原则
   保证每个RowKey都是唯一的 


---      
### 描述HBase中scan和get的功能以及实现的异同？
1. scan是全表扫描
2. get是根据行键获取一行数据
---

### 请详细描述HBase中一个cell的结构？
**cell** 是由rowkey以及列族+属性唯一确定的一个单元,cell数据是没有类型的,全是以字节码的形式存储

---

### 简述一下HBase中compact用途是什么,什么时候触发,分为哪两种,有什么区别?
为什么HFile要进行合并？
1. 那么就要看如果HFile数量过多会产生什么问题？它的读取速度就会下降，因为读取数据涉及到一个操作：寻址
寻址是一个很慢的动作，所以为了防止寻址的动作过多，我们要适当地减少碎片文件，所以需要进行合并这些HFile文件

2. 在HBase中每当有memStore数据flush到磁盘之后,就会形成一个storeFlie,当storeFlie达到一定数量就会进行compact.
3. compact作用:
   1. 合并文件
   2. 清除过期数据和墓碑标记的数据
   3. 提高读写效率
4. 一共有两种合并方式,大合并和小合并
   1. 小合并根据参数选择处理那些小的文件并进行合并,不会进行更新操作
   2. 大合并对整个列族下的所有storeFlie进行合并,最终合并出一个文件


---

### HBase的大合并和小合并
1. 小合并:并不会彻底合并,选部分文件合并操作,不会进行删除清理操作
小合并先按照策略选择文件再进行合并(具体细节不记得,但是大致内容为挑老的和小的合并)
2. 大合并:只要触发就将region下的store下的所有storeFlie执行合并,整合出一个文件,默认是7天1次
我们公司把他禁止掉了,一般都是自己手动合并

合并流程:
1. 获取需要合并的Hfile列表
2. 由列表创建StoreFileScanner,用Scanner读取Hfile的数据
3. 把数据从Hfile读出放到临时文件夹,数据过期的和打上墓碑标记的数据不会被读取
4. 合并Hfile来替换原来的Hfile


---


### HRegionServer宕机如何处理？
Zookeeper首先会监控HRegionServer的上下线情况,如果发现它挂了,就会立即通知HMaster,然后HMaster就会让它负责的region转移到别的机器上,并且会根据WAL回滚日志的操作恢复机器上memStore丢失的数据

---

### HBase在进行模型设计时重点在什么地方？一张表中定义多少个Column Family最合适？为什么？
列族的个数具体看表的数据,一般来说划分标准是看一些数据的访问频度,比如说一张表里面有些列访问相对频繁,而另一些列访问很少,这时候可以把这张表划分成两个列族,分开存储,就可以提高访问效率

---

### 直接将时间戳作为行健，在写入单个region 时候会发生热点问题，为什么呢？
region在Hbase中是按字典排序的,所以如果按时间戳进行排序就会造成一系列的时间操作都会堆积在一起那就会存到一个region里,这样它的region变大,而别的region是小的,加载数据就会变得慢.

---

### 请描述如何解决HBase中region太小和region太大带来的冲突？
Region过小就会发送很多次compact操作,每次都会读一遍重写写到HDFS上,占用IO
如果设置的region过大,就会造成多次分裂,region就会下线影响访问.
所以建议是region大小为256M

---

### hdfs中的数据不是不允许随机修改和删除吗，你刚刚说hbase上的数据存储在hdfs上的，hbase既然是个数据库管理系统，那肯定有crud的功能吧，那这怎么解释呢？
hdfs上的数据的确是不允许进行随机修改和删除的，而hbase中的数据修改和删除也不是直接就修改和删掉了的，是通过数据的标记和文件的合并来实现修改和删除的
比如，hbase数据的删除，对数据的删除，实际上生成了一个新的hfile，并给数据打上墓碑标记
查询数据时，看到墓碑标记，就不会读取这条数据并返回
等到一定条件，hfile合并之后，数据才会消失。

---

### 为什么不建议在 HBase 中使用过多的列族?
1. region过多有可能会查询数据的时候横跨的region多
2. 而且如果列族过多,每个列族里自带的memstore会占内存消耗内存
3. Flush的时候会产生小文件,因为一个store里只要有一个memStore读满了就会把其他region的memStore也刷出来,产生小文件
4. split时候,多个列族数据相差较大,原来挺小的文件也被拆分,产生小文件

---
### Hbase写数据的流程
客户端先去访问Zookeeper Meta表在哪,接着去找有这个表的RegionServer,得到表之后再查自己所要找的Region在哪,然后去请求机器开始写数据.
首先是把自己的操作流程写在WAL中,然后将数据写到memStore上,当MemStore达到阈值之后就会将数据flush到磁盘上形成HFile.

### Hbase读数据的流程
客户端去问Zookeeper Meta表在哪,接着去找那张表的RegionServer去要,得到表之后再查自己所要找的region在哪,然后去请求机器开始读数据.
第一步是初始化自己的迭代器,创建一些Scanner去读MemStore和StoreFile,再读StoreFlie的时候是根据布隆过滤器去判断目标行键是不是在该文件中,根据底层的LSM树快速的找到目标行键所在block,再去查看blockcache是否有这个数据,如果有就返回缓存的,没有就返回磁盘里的,最后把两个Scanner的结果收集到一起合并结果取最新版本返回客户端.

---

### Region怎么预分区
Hbase建表的时候默认单个region,所有数据都会写入这个region,超过阈值会拆分,但是拆分会消耗IO资源且拆分过程region会下线

预分区的主要目的是再创建表的时候指定分区数,提前规划表里面有多少个分区以及它的范围,这样存储的时候行键就能按照分区去存储,这样就能避免热点问题

---

### Hbase的数据结构
Hbase的列族本质上是一颗LSM树,是一种归并排序的思想,LSM树分为内存和磁盘部分0.
1. 内存部分是一个维护有序数据集合的数据结构,就是跳表
2. 磁盘部分是一个个独立的文件组成,每一个文件都是一个数据块,为了磁盘寻址速度快,在文件存储一些额外的二进制数据,这些数据用来判断指定的key是否有可能存储在这个数据块,这个数据结构称为布隆过滤器
3. 布隆过滤器就是为了使得优化LSM树的读性能所加的,但是会增加内存和存储的负担,所以默认关闭

### (扩展)LSM树与B+树的比较
1. 当写比读多的时候,随着插入的操作,为了维护B+树结构,节点会分裂,都磁盘的随机读写概率会变大,性能降低
2. LSM相比于B+树,多次单页随机写变成了一次多页随机写,复用磁盘寻址时间,提高写的性能,放弃一些读性能

### lsm 设计内存部分的目的是什么
主要是用来维护结构,为了防止数据丢失

---

### HBase的memStore的刷写
刷写的条件:
1. memstore级别:当一个region里的任意一个memStore存储达到了上限就会触发(默认是128M)
2. region级别:一个region里的memStore大小总和达到了上限 默认(512M)
3. RegionServer级别:所有memStore的大小总和大于低水位阈值(默认为JVM内存40%)
4. WAL日志级别:日志条数超过上限
5. 定期刷写(默认1个小时)
6. 手动刷


---

### Hbase的HFile的格式
1. data Block段 -- 保存表中的数据 默认一个data block为64kb
2. data Block Index段 -- data block 的索引
3. meta Block段 -- 保存用户自定义的Key-value 包括布隆过滤器的value,key值在元数据的索引块中
4. meta Block Index段 -- meta block 的索引
5. file info -- Hfile的元数据 
6. Trailer 保存了每一段的偏移量

---
### 每天百亿数据存入HBase，如何保证数据的存储正确和在规定的时间里全部录入完毕，不残留数据？(需求)
1. 由于数据量很大,所以不可能用普通写入,这时候就会用到bulkLoad批量导入,这就可以有效的解决数据量大和速度慢的问题
2. 保证数据的正确就需要考虑到RowKey,region分区,列族的设计
---


