
### 分析过的指标
日活 月活 留存 新增 
流式 转化 三天点赞\收藏 热度排行 优惠券人数 点赞

留转G复活指标:活跃 GMV 转化率 留存率

坏房数(因装修不能出售的)
Occ客房入住率 
ADR已售客房平均房价 
RevPAR 可供出租客房的收入 
Revenue月收入
CTP 营业利润贡献
GSS 宾客满意程度指数
MPI 市场渗透指数 
订单量=曝光量X转化率-取消量
1. 民宿房东维度:
   1. 销量收益，合作度，活动参与度，违规评分，三十天内无违规 无拒单 评分 回复率 
2. 用户维度
   1. 搜索场景(同城搜索，异地搜索)，评价率，累积访问次数，性别，年龄，提前预定天数，入住率
   2. 活跃指标: DAU活跃用户数 活跃率 在线时长 启动次数 PV UV

### 做的宽表
访客页面历史记录表
优惠券粒度订单记录表
各省份粒度订单记录表
学生特惠粒度订单记录表
网红民宿信息记录表等等

比如房东房源的订单记录表,我们会往里面塞一大堆维度退下来的,比如评论,比如评分,点赞 70个字段
装修风格,地段,入住率

Occ客房入住率 
ADR已售客房平均房价 
RevPAR 可供出租客房的收入 
Revenue月收入
CTP 营业利润贡献
GSS 宾客满意程度指数
MPI 市场渗透指数 

用户的
签到量
浏览量
点击量
CTR 点击量/浏览量


### 宽表的设计原则,或者说你们是怎么设计宽表的
我们开发宽表就是为了避免重复迭代,得需要了解一下业务全流程,知道需要扩展哪些维度
有一部分的属性描述信息,另一部分就是度量值
设计的话我们就会去思考这个宽表到底会有多宽,能不能少一些字段,然后不要让这个宽表跨主题域
然后分清楚主次关系,做个热词和冷词汇的分离.

### 数据量最多的表
用户行为宽表
多的话能有4-6G左右

### 日活 月活
日活 ： group by 函数 count(distinct)

### 说说你最擅长的业务模板 

### 关于主题
主题:根据统计需求,将具有相似统计特征的内容放在一个分组上,方便后续的计算维护管理等
1. **流量主题**  
   1. 页面分析报表
   2. 会话分析报表
   3. 用户分析报表
   核心的度量比如有pv,uv,会话数,跳出会话数,访问时长等等
   DAU活跃用户数 活跃率 在线时长 启动次数 
   核心的维度有,时间维度,新老访客,地域,终端维度,入口页,退出页等  

   高阶函数 with cube | grouping set |  with  
   类似多维分析主题 广告分析 交互时间分析  运营活动分析

2. **用户活跃主题** 
   1. 会话次数
   2. 访问时长
   3. 连续访问天数
   4. 性别比例
   5. 年龄阶段分布
   6. 新老占比
   7. 地域分布
   中间建了用户连续活跃区间的中间记录表 也就是 字段是区间起始时间和结束时间 
   然后用来做增量的拉链表  节省空间  
   地域也能做拉链表  这样就能记住每次用户地域的变化

   连续活跃报表
   沉默天数报表

 用户活跃区间拉链表主要包含用户id,用户的首次登录时间,区间开始时间以及区间结束时间,用前一天的用户活跃区间表去关联当天的用户活跃明细表,如果之前区间未封闭的用户继续活跃,则该区间不封闭,区间结束时间仍为9999-12-31,如果之前区间未封闭的用户没有活跃了,就该用户对应的区间封死,如果用户之前的区间已经封闭了,该用户再次出现就新开一个区间;

3. **留存分析主题**
   字段 计算日期 首访日期 留存天数 留存人数
   日留存率报表
   周留存率报表

  
用户留存表的开发是我们是基于用户活跃区间拉链表进行开发的,也就是说我如果要计算今天的n日留存,从活跃区间记录表中,找出所有9999-12-31的行且首日登陆小于计算日的,因为活跃的用户就是我们的目标数据，然后datediff函数用今天的日期减去首次登录日期就能的到该用户的留存天数,然后筛选得到留存天数小于n的用户并且进行按留存天数分组聚合得到最终结果




1. **漏斗分析主题**
   1. 推送成单漏斗
   2. 暑期促销成单漏斗

   漏斗分析
   转化率
   点击转化率 预定转化率 支付转化率 学生特权转化率 广告转化漏斗

   曝光 点击 评论区 下订单 支付 


   我们是利用正则表达式去判断用户的行为事件序列的模式，看它是不是匹配漏斗模型定义中的要求
   也就是通过用户行为数据表将各个事件的数据筛选出来(用行转列函数将事件按时间组合起来,然后通过正则匹配的方式去匹配对应的时间序列),然后统计出各个行为的人数除以UV,最终得到漏斗的基础数据

   首先先确定漏斗里面我们需要参与计算的事件对吧
   然后统计一下所有人在这个链路上完成的步数，也就是我们把行为链路按人分组，再按事件排序，然后把完成的事情concat_ws用逗号隔开，用collect_list event组成字符串 也就是比如这链路有e1 e2 e3 e5，然后我们if 正则匹配 e1 为只到了步骤1，if 正则匹配 e1 e2 为只到了步骤2，那现在是这个人完成了第几步骤，我们就需要列转行后sum求和让他变成这个步骤有多少个人完成，然后再除UV看看占比。


   rlike 满足正则
   regexp_extract 从字符串提取正则框定的部分
   regexp_repalce 正则替换 
2. **归因主题**
归因分析主要是为了通过获取用户某个行为的事件链路,分析导致我们用户行为的可能原因,用这个分析的结果去优化一下我们的业务流程，或者放置我们的广告等等。 
   1. 广告位
   2. 可能价格劝退
   3. 展示界面太丑
   4. 打开民宿大图后看到外观就退
   5. 环境
   6. 地理位置

   用到了spark sql + spark core 混编
      1. 先找出做过目标事件的用户
      2. 再从事件明细表中过滤出这些用户所发生的事件记录
      3. 将事件记录数据按照用户分组,然后按时间排序
      4. 我们就每个用户的事件序列,按目标事件为分界点,切分成多段 因为有可能一个用户可能会做过多次触发归因事件嘛
      5. 对每一段按照归因策略算法打分（打分方面我们会有首次归因、末次归因、时间衰减归因、位置归因）


### 你们事实表包含哪些维度和度量 
维度：地域商圈 客群分类 房源描述 住客点评
度量  
Occ客房入住率 
ADR已售客房平均房价 
RevPAR 可供出租客房的收入 
Revenue月收入
CTP 营业利润贡献
GSS 宾客满意程度指数
MPI 市场渗透指数 

浏览量
点击量
CTR 点击量/浏览量

### 拉链表有什么
拉链表多说几个表 用户活跃 用户订单 用户会员等级 订单表 用户会员等级表 用户信息表 用户ip所在地域表

### 什么是缓慢变化维
因为有些维度的属性不是静态的嘛,它会随着时间慢慢的变化,这种就叫缓慢变化维

### 什么是拉链表
拉链表就是对我们收到这个信息的一个历史变动然后我们进行处理的形式嘛,也就是保留了历史的一些状态,还有新增的变化数据.
最新数据为开链数据，历史数据称为闭链数据。

### 拉链表的使用场景
1. 表中的部分字段会被更新
2. 需要查看某一个时间点或者时间段的历史信息(例如某个用户在某一个历史时间点的手机号码)
3. 变化比例不是很大的(


### 拉链表维护计算的基本逻辑
拉链表一个时间维度中同一个用户只保存一条用户状态。拉链表通常会增加三个“开始日期start time、结束日期end time、状态标识mark。我们就用当前数据通过主键与历史数据进行对比，判断当前数据与历史数据是否发生变化，如果发生变化就进行相应的开链、闭链操作。

### 拉链表补充
- 查询性能：随着时间的推移，拉链表会越来越大，查询性能也可能会有所下降
  保留部分历史数据，比如说一张表里存放着全量的拉链表数据，我们只对外提供一张近3个月数据的拉链表。
- 使用拉链表的时候可以不加end_date，但是加上之后，能优化很多查询；
- 可以加上当前行状态标识，能快速定位到当前状态；
- 在拉链表的设计中可以加一些内容，因为我们每天保存一个状态，如果我们在这个状态里面加一个字段，比如如当天修改次数，那么拉链表的作用就会更大。



### 缓慢变化维有几种 
1. 第一种方式是直接覆盖原值
2. 第二种方式是用代理键去区分历史数据和新增数据
3. 第三种方式是添加新的字段去区别历史和新增


### 做过最难的指标
流量主题下的页面给予下游的贡献量
用sql把头皮抠出来都想不出 
然后去网上借鉴,去问问大佬,就知道可以用算法来实现
大致的步骤就是构建一个二叉树去便利每个页面的子页面,也就是用到了树的后序层次遍历
封装好方法写成dataframe 注册成UDF写spark-sql实现


### 数仓每天跑多少表 
150来张吧 
业务数据40张左右 
datax 20分钟左右
每天1点执行 五个小时跑完



### 测试环境
和生产环境电脑配置一样的 三台 

### 怎么保证sql的正确性
就是ADS的报表和mysqL的结果比对一下
或者就是抽取生产环境的2000条数据然后运算核实一下
测试完之后打包脚本 然后跟总监和运维说一下,运维负责上线.


###  你了解的业务域的分析报表: 做过哪些报表  指标有什么 维度什么
业务域我不是很了解,我主要做的是行为域的数据,但同事叫我拉过去帮他们写过sql,自己也稍微了解过一些
大致的内容就是我们会有很多张业务表要进行历史数据的勘察嘛,我们用的工具是DataX,
**对于那些不怎么变化的表,比如字典表啊,地域表啊,积分规则表那种写死了的表,我们就会全量导入到ODS层嘛,**
**而那些数据会不断变化或者是新增数据的表,比如订单表,会员信息表,优惠券领取表这种我们就会每日增量去导入,**
然后将这张表做成拉链表的形式放到dwd层,一般用的星型模型去建立报表,如果统计需求过多我们会提前弄一张宽表存到dws层.
然后我最近做过有关订单的报表,度量总客单价啊,实付金额,优惠金额,
维度有那些性别,地域,会员等级,支付方式等

