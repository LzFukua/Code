###100万个数字的文件乱序排列,使用何种算法进行排序
希尔排序 具体思路是先拆分成若干个小的 然后再排


###hive的排序优化 
select * from(select name,Company from haha distribute by Company sort by Company)t order by Company
distribute by控制reduce如何处理数据，sort by 控制reduce的数据如何排序

Order by大哥力大无穷，可发挥全局排序大法，但是这逼在数据量很大的情况下，常常会跑不出来。
sort by二弟其力量是对reduce的单个输出进行排序的，木有全局排序的魔法。
distribute by小哥 可以按指定字段将数据划分到不同的reduce中 妹有排序的功能。


###你们的ODS层设计了多少张表?最大的一张表有多少数据量
我们公司有业务表和行为表,我负责的是行为域,大概十多张吧,因为来源渠道不是很多,大致包括app端,网页端,小程序端什么的,最大的一张表是app用户行为数据表,每天的数据条数会有亿级别


###项目建设层设计到的数据调研和探索的内容大概有什么
和业务需求人员对接,数据保留的时间,数据重要的字段,统一口径字段等等

###ODS到DWD层的字典码内容转换你们是怎么做的?
建立一张维表统一字段,使用的时候做关联

###一般ODS层到DWD层,任务报错了怎么处理
1. 先去查看hive和spark的web页面或者日志查看报错原因,然后定位解决
2. 如果不是hive和spark的问题,那就是脚本问题

###数组源里面的脏数据你们是怎么处理的
我们对于核心字段缺失的就直接过滤掉了,然后只是游客登录的空账户信息,我们会做一个全局的Guid去处理这个(然后blabla说怎么处理的guid)

###宽表的设计原则,或者说你们是怎么设计宽表的
我们的宽表需要根据需求文档确认度量和维度,选取对应主题下中心事实表和维表,然后关联之后得到宽表


###有没有遇到过什么业务场景RDD比sql好用的
1. 在那种数据源为非结构化数据的时候,我们对数据进行预处理,什么session切割啊,脏数据剔除,字段信息补全,空值填充的时候,sql干不了,RDD就派出用场了
2. 做归因分析的时候我们也会用到RDD,因为一个用户有可能触发多次目标事件,然后我们在建模的时候就会需要去切分多段来给他打分


###UDF的使用 
我们在做地理位置回补创建字典表的时候,将经纬度退化成geohash值就用到了UDF


###Hive数据倾斜或者跑得慢怎么定位的然后排查和解决
1. 跑得慢的情况下,对于我来说我就会首先去看UI界面去查看是哪部分任务跑得慢,然后去看是否是资源分配不足,如果不是再去看对应的任务sql,排查是不是空值倾斜或者字段倾斜的问题,又或者是能不能开启mapjoin来解决shuffer问题
2. 但我知道的主要的解决方法其实是查看hive执行计划,然后找到具体的stage,根据提示信息得到相应的问题然后去更好的解决,但自己还没总结得够,需要去百度或者问别人来帮忙查看解决,自己还在学.


###根据业务的小文件情况,怎么产生的怎么解决的

###你们项目为什么要引进数仓


###sqoop默认几个Map?
4个