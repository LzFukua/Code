### Kafka在Zookeeper中存储的信息有哪些？
1. broker相关信息
2. 控制器所在broker的信息
3. 所有消费者的信息
4. 集群管理信息 (partition重分配信息,最优选举leader的副本信息,近期删除的topic信息)
5. ISR变更信息


### kafka有哪些特点
1. 高吞吐量 低延迟(因为是顺序读写且零拷贝机制)
2. 可扩展
3. 容错性
4. 高并发
5. 可扩展性

### 为什么要使用kafka 
1. 给上游数据的缓冲与削峰的作用
2. 而且作为流式数据的数据源

### kafka的架构
1. 整体架构为 生产者 Brokers 消费者
然后重点是topic 和他的partition 

### kafka分区的目的?
实现负载均衡 提高kakfa的并行度

### kafka的传输语义(acks)有几种
1. **acks** = 0 意味着如果生产者发送了出去就代表已经成功写入kafka 
2. **acks** = 1 意味着leader收到消息且返回应答就代表已经写入到kafka
3. **acks** = -1/all 意味着所有ISR都要返回应答才会认为写入到kafka

### kafka采用的是Pull,为什么
1. pull模式下可以自主决定是否批量的从broker拉取数据,且会根据运算资源去调度消费,只是缺点是会不断的访问是否有新数据到达,但是为了避免这一点,kafka有个参数可以让consumer阻塞直到新消息到达就能解决这个问题.
   
### kafka的存储结构
1. 物理上的存储结构是,有索引文件,时间索引文件,数据存储以及leader纪元文件
2. 消息存储结构是,校验内容crc,kafka版本magic,key value 以及他们的长度,还有一个压缩类型attributes

### kafka 创建Topic时候是如何将分区分配给Brokers的
第一个分区的第一个副本是随机发放到某台broker上,接着轮询往给后存放副本

### kafka的分区数只能增加 不能减少

### 消费者和消费者组的关系
如果只有一个消费者,那他自身也是存在在一个消费者组里,消费者组的意义就是可以共同的去协作消费一个topic的数据达到分布式的思想,且一个分区只能被一个消费者消费

### 谈谈kakfa消费者组的分区再均衡机制
1. 触发再均衡机制一般有 组内成员发生变动 还有 分区增加/topic发生了变动 就会产生再均衡机制
2. 而再均衡有四种策略
   1. range策略 也就是topic分区数除以消费者数得到 的每个消费者该得到多少分区 且前面的组员会多得一些
   2. round策略 按轮询的方式获得分区 但有可能会乱序
   3. Sticky策略 去尽可能的保留原来消费者所负责的分区再去均衡
   4. Cooperative策略  完善了不会去将所有的分区取消再去均衡的策略,而是去拆解为多次小均衡来达到全局均衡

### kafka的监控你们用什么
kafka-eagle 但现在改名了好像 叫 EFAK


### kafka控制器Controller的作用
管理broker的上下线,以及所有topic的分区副本分配和leader选举的工作

### 名词解释 ISR OSR AR LEO HW LSO LW
ISR:副本同步队列
OSR:没跟上leader暂时被踢出的副本
AR :所有副本

LEO:日志文件中的下一个偏移量
HW :高水位 指的是AR最小的LEO
LSO:是指事务的第一条消息 如果没开启事务就没意义
LW :是指低水位 代表AR最小的logstartoffset的值


### kafka生产者的数据发送流程 (写流程)
1. 调用kafkaProducer send方法
2. 将数据传入拦截器对消息进行过滤或者加工处理
3. 将消息传入序列化器
4. 然后分区器去发送到消息累加器里面进行分区缓存
5. 另一个sender线程不断从缓存区取数据出来
6. 创建requester网络请求,一边发送到selector去连接broker发送,一边做缓存
7. 如果发送失败了,就可以从缓存区里重试发送
8. 如果发送成功了,就清除缓存 

1. 连接到 zk 集群，从 zookeeper 中拿到对应的 topic 的 partition 信息和 partition 的 leader 的相关信息
2. 连接到对应的 leader 对应的 broker
3. producer 将消息发送到 partition 的leader上
4. leader 将消息写入本地 log， follower 从 leader pull 同步消息
5. 写入本地 log 后，依次向 leader 返回/发送 ack



### kafka消费者读数据的流程(读流程)
1. 连接到 zk 集群，从zookeeper 中拿到对应的 topic 的 partition 信息和 partition 的 leader 的相关信息
2. 连接到对应的 leader 对应的 broker
3. consumer 将自己保存的 offset 发送给 leader
4. leader 根据 offset 等信息定位到 segment（索引文件 .index 和日志文件 .log ）
5. 根据索引文件中的内容，二分查找定位到日志文件中该偏移量对应的开始位置读取相应长度的数据并返回给 consumer


### Kafka 消费者角度考虑是拉取数据还是推送数据
从消费者角度考虑的话是拉取数据,因为如果是被推送数据的情况下,推送速率要大于消费者消费速率,那么消费者就要挂掉了,而pull模式下可以根据消费者的能力去拉取数据,只是pull模式下会导致一直轮询的去问是否有新数据,但可以设置参数让消费者处于堵塞状态直到有新数据出现


### kakfa数据怎么保证的一致性 
首先kafka做了一个 HW,是AR最小的LEO,来保证可读的时候所有副本消费出来的数据都是一样的,但问题在于,副本知道水位线的时候都是漏一拍才能知道水位线在哪,此时宕机了leader更换就会导致数据丢失,而0.11版本之后添加了一个叫leader-epoch机制,来使得数据不会因为leader变更时导致数据丢失和不一致,因为他会记录每个leader偏移量,然后再去让follower从他这个朝代的偏移量开始以前的截断数据且只记录当朝的.


### kafka怎么保证数据不丢失(容错性)
如果说到kafka深层原理的话,kafka是不能保证数据完全不丢失的
在Producer端丢失数据
1. 在生产者的方面 由于有应答机制,如果不是-1的情况下就会有可能丢失数据   
2. 在broker方面来看 刷盘时如果突然宕机,选举了一个落后了很多的当选成Leader也会丢失数据
3. 在消费者的方面 由于数据默认为自动提交偏移量,或者是半自动的提交偏移量 所以就会有数据丢失的现象,认为你已经消费过了
   
所以策略为
生产者端
1. 设置callback来使得生产者发完数据后会回调通知函数
2. ACKS设置为-1
消费者端
1. 取消自动提交偏移量的方法 采用手动提交偏移量

### kafka保证数据不重复
1. 生产端开启幂等性
2. 可开启事务或者是手动提交偏移量,利用mysql/redis的事务来达到去重目的

### kafka如果数据积压了,消费能力不足怎么办
1. 如果是消费能力不足,那就增加topic的分区,提升消费者的数量
2. 或者是提高每批拉取的数量



### kafka怎么实现高吞吐低延迟
1. 顺序读写
2. 零拷贝（跳过用户缓冲区拷贝，直接映射磁盘空间和内存）
3. 批量发送 生产者缓存本地，等条件触发了才发送到broker
4. 数据压缩
5. 分区