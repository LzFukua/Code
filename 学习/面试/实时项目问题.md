### 项目介绍
我们战略之眼这个项目严格意义上的来说是是一个事件驱动型的应用，不属于通常的数据统计开发，是一个强推荐，强业务导向的系统，主要的功能为我们的业务人员在web端经过圈选好所指定的人群，然后通过实时监测app在线用户的行为和他们的画像特征，然后对该用户进行规则匹配来触发一些营销手段。
举个例子，比如对消费能力等级在3以上，并且在最近5天内有过重庆民宿收藏，当她再次搜索重庆民宿的时候，就立即给她推送一个分享领券的活动通知，让她分享到朋友圈获得代金券从而促成她的下单消费；

1. 架构想象为一张图，上半部分为数据静态接入模块，而左边为从kakfa实时采集用户行为日志后预处理得到的数据，存入到Doris中，右边为离线数仓组所提供的用户画像，以ElasticSearch存储。
2. 中间部分为规则注入管理模块
   1. 那运营人员会选择人群以及制定规则嘛，发送过来的json串，我们是以enjoy模板代码来动态解析更改，然后以groovy脚本去注入，人群圈选就会将人guid形成bitmap，然后一并存入到Mysql元数据库里，而后续的增添规则或者维护工作，我们只需要去修改Mysql元数据库就能实现。
   2. 到这里，Doris里面的历史数据就做为规则条件的初始值，将Doris的数据放入到redis集群中作为Flink的状态，就比如我今天发布规则，而我圈选的日期是横跨了历史和未来的，那么所用到的历史数据就从Doris来。
3. 下面部分为规则计算引擎模块，也就是Flink接kafka的实时数据与从Mysql的规则模板表用Flink-CDC监控然后广播出来进行连接，然后将数据进到每个规则运算机去判断是否符合条件，符合条件的就将运算结果输出出去，而不符合就让Redis状态数据进行变化，一直到该用户规则满足后再触发。
项目的大体就是这样。


### 为什么不用Flink CEP
一开始的时候，我感觉这个需求跟flink cep的适应场景很匹配，可是后来跟需求那边详细沟通了一下后，发现他们有一个非常关键的需求点就是： 要求能够在job不停的情况下，在线动态地改变运营规则，比如可以发布新规则，下线已运行规则，或者重新上线已经停用的规则，修改已运行中的规则的参数等等，而且都要求能够实时生效；

所以如果用flink cep的话，一旦把规则写好，就定死了，如果需要动态增加或者修改规则，必须新开发job，或者修改原来的代码，然后把原job下线再上线新的job，无法满足营销人员的快速灵活营销需求；

所以我们是自己设计了一套机制和逻辑，来实现这个系统；用到的技术栈主要就是flink的cdc、广播、processFunction，另外还有用于注入动态逻辑的groovy，还有就是用于查询行为明细的doris库和查询画像属性的ES；


### 为什么要用redis
1. redis对外开放，需要对运算结果或初始值等进行人为干预的话，很方便
2. redis中有丰富的数据结构，将为我们的滚动增量运算逻辑设计带来巨大的潜在的帮助
3. redis本身的读写速度与flink内部的state不相上下，能满足我们的高并发低延迟读写要求


### redis 标签存储格式
规则序号：条件序号 --> （guid,次数）


### 你们的qps多大?
您是说app嘛，我们公司月活60-80万左右,峰值时候同时在线人数4万,qps为3000-4000。
flink配置了12台服务器

### 日活 月活 数据量 条数 
70-80万   300万  100G数据   


### 为什么要用Kafka而不用MQ这种
1. 在消息队列这个圈子里Kafka是当下最流行的，认可度也是最高的，社区支持力度最高的
2. 高度成熟的技术和庞大的生态可以兼容当下所有的主流计算引擎，丰富成熟的API也对开发者友好


### 规则sql模板存在mysql的字段
1. 规则模型id
2. 条件类型 大于小于
3. sql模板 text
4. 作者
5. 审核人
6. 创建时间
7. 修改时间

### 规则引擎资源字段
1. 模板id
2. 规则id
3. bitmap
4. json
5. groovy代码
6. 状态上下线 

### 规则模型计算模板
规则计算机 


### 难点之一 动态Keyby
我们的规则需求中，一开始，运营人员所指定的规则，在计算时基本上都是按照用户为单位进行计算，所以，我们的整个处理逻辑中，是把数据先keyby（用户id）后，再进行核心逻辑的计算的；  但是后来，需求那边偶尔也会提一些“风控类”的规则，比如“同一个ip地址在指定时间跨度内，出现过N次登录密码错误”等规则，那这些规则对匹配计算的逻辑上，需要按照ip字段来进行keyby

所以，如果代码中把keyby写死，则无法适应上面所说的这些需求了；

为此，我们设计了一个动态keyby的方案；
简单来说，就是，首先要在注入的规则参数中，要按照我们的规范指明：这种规则的匹配计算需要按照数据中的哪个字段进行keyby
然后，在我们的数据处理逻辑中，我们会先把数据按照各个规则中的keyby要求，提取出所需要的所有“keyby”类型，比如（有按deviceid的，还有按ip的），那么，我们就利用反射手段，从数据中提取出指定的这两个字段的值，然后把一条数据“复制”成两条，分别带上deviceid的值和ip的值，并命名为“keyByField”字段，后续在keyBy时，就写 keyBy(bean->bean.keyByField)就ok了.


### 你们用的什么什么时间语义？万一有数据延迟到达怎么办？
我们的这个项目强调的是**时效性**，而不是数据统计的**完备性**
如果用时间事件语义，那么当数据乱序迟到时，可能会导致我们整个时间推进延后！不符合我们的时效性要求！
我们在这个场景中，采用的是process time时间语义，而且，我们的程序并不是用window算子等来实现的；而是处理逻辑完全由我们自主控制的，我们可以在规则运算机中根据需求，判断当前的系统时间以及到达的事件的行为时间，是否满足我们的要求做出不同的处理！


###  发布规则之前会查询动态画像条件历史值并发布到状态，然后规则再上线运行，这中间有一点时间差，那么，是不是会产生计算的遗漏？
哇这个问题好牛。
这个问题确实存在！
只是，在咱们这个智能运营的场景中，能够容忍一定程度的不精确；
另外，这种漏算数据的概率其实也很小，第一，时间差很小；通常在10s以内；第二，在这段时间差内，用户的行为数据中也不一定就包含规则条件中所需要的事件；

当然可以，我们在下一个版本的迭代计划中，已经设计了相应的方案，而且在测试环境中已经经过了测试；
方案是这样的；
1. 规则运算机的设计中，要添加一个功能，能够一次性接收一批用户行为事件进行处理；并且规则运算机还需要带一个标志（是否是第一次上限运行）
2. flink引擎中，添加一个机制：
  1. 收到一个用户行为事件，遍历每一个规则运算机
  2. 判断该规则运算机是否是第一次运行；
    1. 如果是，则将存储最近30s用户行为明细的数据状态交给规则运算机进行批处理；批处理完后，把当前这条收到的行为，再交给状态机进行正常处理！
    2. 如果不是，则将当前这条数据交给状态机正常处理！
    3. 最后，把当前这条行为数据保存到状态