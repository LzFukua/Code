### 项目介绍
我们战略之眼这个项目是一个强推荐，强业务导向的系统，主要的功能为我们的业务人员在web端经过圈选好所指定的人群，指定一系列的触发规则条件，于是当用户达到条件时就会触发弹窗或是横幅等一系列营销推送的内容。
1. 架构想象为一张图，上半部分为数据静态接入模块，而左边为从kakfa实时采集用户行为日志后预处理得到的数据，存入到Doris中，右边为离线数仓组所提供的用户画像，以ElasticSearch存储。
2. 中间部分为规则注入管理模块
   1. 那运营人员会选择人群以及制定规则嘛，发送过来的json串，我们是以enjoy模板代码来动态解析更改，然后以groovy脚本去注入，人群圈选就会将人guid形成bitmap，然后一并存入到Mysql元数据库里，而后续的增添规则或者维护工作，我们只需要去修改Mysql元数据库就能实现。
   2. 到这里，Doris里面的历史数据就做为规则条件的初始值，将Doris的数据放入到redis集群中作为Flink的状态，就比如我今天发布规则，而我圈选的日期是横跨了历史和未来的，那么所用到的历史数据就从Doris来。
3. 下面部分为规则计算引擎模块，也就是Flink接kafka的实时数据与从Mysql的规则模板表用Flink-CDC监控然后广播出来进行连接，然后将数据进到每个规则运算机去判断是否符合条件，符合条件的就将运算结果输出出去，而不符合就让Redis状态数据进行变化，一直到该用户规则满足后再触发。
项目的大体就是这样。



### 为什么要用redis
1. redis对外开放，需要对运算结果或初始值等进行人为干预的话，很方便
2. redis中有丰富的数据结构，将为我们的滚动增量运算逻辑设计带来巨大的潜在的帮助
3. redis本身的读写速度与flink内部的state不相上下，能满足我们的高并发低延迟读写要求

### redis 标签存储格式
规则序号：条件序号 --> （guid,次数）


### 你们的qps多大?
您是说app嘛，我们公司月活60-80万左右,峰值时候同时在线人数4万,qps为3000-4000。
flink配置了12台服务器

### 日活 月活 数据量 条数 
70-80万   300万  100G数据   


### 为什么要用Kafka而不用MQ这种
1. 在消息队列这个圈子里Kafka是当下最流行的，认可度也是最高的，社区支持力度最高的
2. 高度成熟的技术和庞大的生态可以兼容当下所有的主流计算引擎，丰富成熟的API也对开发者友好


### 规则sql模板存在mysql的字段
1. 规则模型id
2. 条件类型 大于小于
3. sql模板 text
4. 作者
5. 审核人
6. 创建时间
7. 修改时间

### 规则引擎资源
1. 模板id
2. 规则id
3. bitmap
4. json
5. groovy代码
6. 状态上下线 

### 规则模型计算模板
规则计算机 