a1.sources.s1.batchSize = 200 默认为100
一次性读取的event的数量

a1.channal.c1.capacity = 1000000 最大为一百万
作为缓存数据的容量 容量一定要大于bacthSize

a1.channal.c1.transactionCapacity =  5000  
事务容量 处理的事务中所有的总事件之和
事务容量 大于 batchSize  小于 capacity  

事务能保证事件不会漏采,但不能保证事件不会多菜

a1.sinks.k1.hdfs.batchSize =  200 
一次性写入HDFS的event的数量

通说事务的问题 (也就是数据丢失以及数据多采的事情)
在flume中事务包括put事务和take事务,数据会保证在source到channel,以及channel到sink阶段不会丢失数据,但并不能保证数据会重复
1. 首先是put事务,source会采集一批数据封装为event,调用doput方法,将这批event写到临时缓存区putlist(putlist大小由transaction capacity参数控制),然后进行doCommit,检查channel内存是否能装得下,装得下就提交成功,装不下就进行回滚操作,将整个putlist数据全部扔掉,然后返回异常给source,再次重新提交一次数据.但可能汇报完成的时候汇报失败,但已经将数据写到channel里了,这就会导致数据会重新采集,造成数据重复.
2. take事务中的dotake方法将数据剪切取到临时缓冲区takeList,同时也拷贝一份放到HDFS的io流中,然后进行doCommit,如果发送成功,就清除掉takelist的数据,如果失败就进行回滚,但这时候可能会导致数据重复,如果写入了一半的event到了HDFS上,但回滚的时候会将整个takelist归还回channel然后再重新拉取.


级联
Avro Sink (为了数据的安全不被上下服务器操作机器所使得数据不安全,所以在agent中设置了跳板机来做隔离)
上游agent  改动sinks
a1.sinks.k1.type = avro 
将Event发送到的服务器 认识的域名或者是id
a1.sinks.k1.hostname = hadoop001
保证端口号一致
a1.sinks.k1.port = 66666
a1.sinks.k1.channel = c1

下游的agent可以使用上游拦截器所设置的数据

级联 下游agent 改动sources
a1.sources.s1.type = avro
a1.sources.s1.bind = 0.0.0.0  代表接收所有的服务器请求 如果只写单个 要写本机
a1.sources.s1.port = 66666
a1.sources.s1.channels = c1

failover
但如果跳板机只有一个的话宕机就完蛋了,所以应该提供高可用保证不会因为故障导致数据积压
failover sinks 组
这些是上游配置的
a1.sinkgroups = g1 
a1.sinkgroups.g1.sink = k1 k2
a1.sinkgroups.g1.processor.type = failover 自动的主从切换
a1.sinkgroups.g1.processor.priority.k1 = 10 谁大谁做主sink 权重 
a1.sinkgroups.g1.processor.priority.k2 = 3 
a1.sinkgroups.g1.processor.maxpenalty =  30000(ms)  退避时间  每30s去问问主sink活了没
然后将下游配置文件发到不同机器上就可以实现完成多个跳板机


在上游传递到下游的数据 可以使用压缩来提升效率 
a1.sinks.k1.compression-type deflate 压缩模式
a1.sinks.k1.compression-level = 6 压缩率


还可以使用多线程的操作,在下游写
a1.sources.s1.threads = 4 
a1.sources.s1.compression-type = deflate 与上游的要保持一致


选择器(为了让sink高效率传递,实现负载均衡) 在下游的sink进行操作
有三种策略
1.副本 每个channel分配一样的数据
2.负载均衡策略 1随机数 2轮询
3.操作数据头的方式进行映射选择,可以自定义映射规则


a1.channel = c1 c2 
a1.sinks = k1 k2 


配置自定义拦截器2
删了 a1.source =s1.channels = c1 换用选择器的方案
配置下
a1.sources.s1.interceptors = i2
a1.sources.s1.selector.type = multiplexing
a1.sources.s1.selector.header = state
a1.sources.s1.selector.mapping.0 = c1 
a1.sources.s1.selector.mapping.1 = c2


然后把整个channels  和 sinks 都复制创建 c2 k2  ,配置文件channel更改缓存存储文件路径 2 
a1.sinks.k2.channel =c2 ..  以及后面的输出hdfs参数都改为k2

修改脚本每个机器清理 以及删除脚本

