
operatorstate 用来绑定非keyby的数据   例如记录偏移量的 
 

RedisCommand.HSET 调用redis的hset方法写入 有就覆盖 没有就添加 (聚合类的就用HSET 不聚合就用List,就是不停加进去的 )

statebackend的数据不是实时变化的 得完成一次checkpoint之后才会变化 checkpoint之后会把状态的kafka偏移量+数据都保存在Statebackend中
所以如果上一次checkpoint成功了,下次失败之后,jobmanager将所有的subtask全部释放掉,重新从Statebackend中去恢复状态,存放到redis覆盖写


AtLeastOnce 语义  至少一次 但是有可能会重复消费

但是默认是放在jobmanager的内存里,如果jobmanager宕机了数据就丢失 所以要放到HDFS或者RockDB中

默认情况下 flink的sources读取完数据,会将偏移量写入到Kafka特殊的topic中 
如果开启的checkpoint就得使用checkpoint,就会用到状态数据恢复偏移量,而不会使用kafkatopic中的
设置   .setCommitOffsetsOnCheckpoints(false)  //checkpoint成功之后就不将偏移量写入到Kafka特殊topic 

保证偏移量:开启checkpoint 且将Statebackend设置为到HDFS里

OperatorState的底层是List 可以存多个不同类型的值
KeyedState的底层是Map

AtLeastOnce语义: 


以后状态都要transient修饰  
以后这个状态就只能通过initializeState 或者 open方法初始化或恢复数据 不能在客户端指定默认值


为什么keyedstate在open里初始化,operatorstate在initial里面初始化 
   因为initial既可以初始化 keyedstate 也可以初始化 operatorstate  
   这是一种书写习惯 证明operatorstate功能其实会比keyedstate更强大


checkpoint 必须所有subtask都ack给jobmanager 这个checkpoint才算成功


env.getCheckpointConfig().enableExternalizedCheckpoints(CheckpointConfig.ExternalizedCheckpointCleanup.DELETE_ON_CANCELLATION); //默认是这个 就是cancel掉就删除checkpoint记录
env.getCheckpointConfig().enableExternalizedCheckpoints(CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION); //建议加的是这个,这个任务cancel掉会保留checkpoint记录

不建议用web页面的cancel命令  而是使用Linux的 bin/flink  stop -p hdfs://地址 意思是main方法参数    -p 意思就是当前状态保存到指定的目录
checkpoint 和 savepoint 的区别  
checkpoint指的是周期性的做的具体的某一次检查点,把状态保存到指定的目录
savepoint是人为停止job后手动做的保存指定目录 
savepoint的数据比checkpoint会比checkpoint的新
因为手动调用stop命令时候,会将job中最新的状态保存到Savepoint中  
(cancel命令已经过时了 现在都用stop)

如何用命令提交任务 +
把jar包上传上去 然后 /bin/flink run -p指定并行度  -s指定savepoint或checkpoint路径(必须指定到保存state文件的上一级目录)    /xxx.jar jar包  hdfs://地址 意思是main方法参数



