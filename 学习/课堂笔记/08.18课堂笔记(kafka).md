topic 类似于表的概念
partition 类似于 Hbase中region的概念
replication 副本 类似于hdfs里面的副本 --> 分等级 leader和follower 

kafka 消息中间件  严格意义上不是消息队列
缓存系统 1.解耦 2.削峰填谷      
特点: 
吞吐量大 
读写快
高并发
容错性
可扩展

mysql不能动态扩容



redis 存储量小 而且很难控制读写顺序
实时必须保证读写顺序

kafka主要应用于大数据的流式计算中的数据缓冲

建立topic不可以用下划线和点 

新兴  pursar  也是消息中间件


kafka无法百分百保证数据读写的先后顺序一致
可以保证分区内的读写顺序一致

kafka不适合需要顺序的 例如金融场景 可能会因为顺序不一致导致结果不一样  应该要用别的手段
或者是让kafka这个分布式系统改成单机系统
把数据的分区系统设置为1 


1. 从最开始进行消费
2. 从最后开始消费
3. 从我指定的未知开始消费
4. 从上消费完的未知开始消费


1. 服务器叫brokers 可以有很多台
2. 客户端 写数据的叫 producers
3. 读数据叫consumers

数据分类的隔离概念: topic
数据会以topic来进行和底层的分割 
然后topic内会被分割成若干个partition
每个partition都可以有多个副本  

每一台broker都把自己管理的数据存在自己的本地磁盘


对zookeeper有依赖 
汇报在线状态 以及元数据信息都放在zookeeper上


开源软件的源码 基本上都是托管在github上 去里面看pom.xml依赖文件找到对应的组件版本

运维监控平台 kafka eagle
可以更快的知道kafka的状态信息

kafka默认对客户端暴露的连接端口是 9092 
zookeeper默认的对客户端连接端口是 2181
namenode是 8020

-daemon的意思是 启动在后台 后面需要加config/

kafka egale默认的数据库是sqite  类似于 derby 一种嵌入数据库 


kafka-topic.sh --zookeeper hadoop001 --describe --topic topic-xxx 查看topic内容 分块等
               --create --replication-factor 3 (副本有几个) --partitions 3 (分区)  --topic test(名字叫什么)

replicas 所有副本所在的broker
isr : 在同步中的副本 


kafka删除 需要开启 delete.topic.enable = true

kafka-topic.sh --zookeeper hadoop001 --alter --topic xxx  --partition 3 
增加分区 但是只能增加不能减少 原因是减少分区的代价太大了 数据需要转移 日志需要拼接
完全可以重新创建主题然后复制过去

--config 动态配置topic参数 去官网找文档可查


生产者 
kafka-console-producer.sh --broker-list hadoop001:9092 --topic xxx
(然后就可以开始写数据)
1,zs,18 --> 然后就会传到topic xxx里面去

消费者
kafka-consle-consumer.sh --bootstarp-server hadoop001:9092 --from--beginning --topic xxx
消费的起始偏移量有三种策略 earliest 从最早的消息开始消费
                         latest   从最新的消息开始消费
                         指定offset: 从你指定的位置开始消费

--from--beginning 会从头开始消费 如果重新开启 则会打乱顺序 原因是各个分区内排序了 但是总的没排序
如果不写 就会从最新的消息
--offset (指定偏移量一定要写分区)
生产者把数据写入到topic 默认是吧数据在多个partition之间轮询写入
所以每个分区 都有offset=0这个消息 所以各自会有顺序写入


如果topic中的数据量大 而你需要多个并行处理任务 就需要(消费组)
消费组内的各个消费者之间,分担数据读取任务的最小单位是 partition 
也就是一个partition只能被一个消费者读 不能分担读
kafka-consle-consumer.sh --bootstarp-server hadoop001:9092 --from--beginning --topic xxx --group xx

kafka中的消费组 可以动态增减消费者 而且消费组中的消费者发生任意变动 都会重新分配分区消费任务


消费偏移量的记录
如果不指定beginning 则会从上次消费的记录偏移量开始往下消费
偏移量记在kafka内部的topic中 系统自己生成的 __consumer_offset 序列化形式
consumer去记录偏移量的时候 是周期性的定期提交当前的位移 不是一批记录也不是一条记录一次 