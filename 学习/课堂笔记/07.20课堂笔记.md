1.选择器/脚本/没有手敲,以及没有把配置文件上传到机器上 


数据量计算 
每日的数据规模:数据的规模根据公司的业务和公司的用户规模活跃度决定

峰值一般会到平常的 2 3 5 倍

链家 7000万用户  300-400万活跃度 
差不多10多秒产生一个数据 
一个人一次事件产生1.2kb
每个活跃用户平均产生70-80条数据 
每个人一天的事件大小85kb左右
每天280-350多G  
平均公司 按最大的来算就3.5M/s的数据
高峰期35M/s 

日志采集服务器  三台 一台30M/s的传输速率  

下游服务器 两台 网络带宽150M

写在HDFS上也差不多40M/s的速度 富裕配置

总用户/活跃用户/访问时长/业务特点/每个人平均每天产生多少条日志/每条日志大概多大/平均每天产生多少条日志/日志的总大小/平均每秒多少数据(大小或者条数)

业务高峰期在毕业季 或者是年后

富裕配置 考虑到了高峰期 且保证了性能和速率和容错


数据是否有积压 一开始有 后来做了优化后就没了
一开始只有一台跳板机,宕机了就直接积压在上游,所以我们就多设了两个跳板机去做高可用,且带宽也很猛150M左右,然后下游输出到hdfs上的sink用了选择器做了sink组用来负载均衡,所以不会有积压现象了.


TailDir source 大概30M/s 看硬件 自己吹  
avro 传输速度150M/s 网络传输 公司的带宽
多个sinks写到HDFS上 不用加机器

nginx只负责分配任务给机器,所以如果宕机就不给你任务

数据采集延迟的问题 你们公司是否会有延迟 
1. app上报延迟
2. SCS之间的batch操作
3. 网络延迟等

怎么处理
1. 将统计计算任务向后推一个小时,计算任务在第二天1点计算
2. 在四点的时候去写个检查行数的脚本与一点的进行比对,根据延迟阈值,判断是否重新计算.
如果重新计算,而还有数据没到,就不要后面不到的数据了,而如果不打算重新计算,就直接不计算延迟的数据



数据重复怎么解决
统计在日志端生成的行数,再统计已经到HDFS上的行数,两个行数进行对比,如果多了就是重复,写个程序进行去重操作

在进行报表统计的时候再去重,计算压力是再后面的数仓中

大多数都是入库前去重


cat a.txt | wc -l 统计行数 

hdfs dfs -text /xxx.txt | wc -l 

-text可以解析压缩后的文件 


javaweb 业务 数据管理/质量监控平台
流程是 每台日志服务器以及HDFS 上报每日自己产生的日志条数 传到 meta-bus中
存到Mysql中  可以查询每日数据采集是否重复
还能监控日志采集活跃度
还能监控hdfs运行情况 占用内存什么的 



CRUD 增删改查
sInk.hdfs.fileType 压缩格式 
默认为sequenceFile 
里面有dataStream 和 CompressedStream
用不支持压缩就写dataStream
设置compressedStream就必须写 hdfs.codeC =gzip / bzip2 / snappy 






