归因事件分析
1. 首次触点归因策略  第一个事件占全部
2. 末次触点归隐策略  最后一个事件占全部
3. 线性归因策略 每个事件都平摊归因
4. 位置归因 (U型归因)
5. 时间衰减归因策略 随着时间因果关系越来越大 


spark 不支持hive的map的映射格式  properties[p1:v1,p2:v2] 的显示 所以需要做成orc的格式





OLAP 在线联机分析  对的是海量数据 查询数据

OLTP 在线联机事务  对数据进行增删改查 做业务处理 事务能保证数据安全 业务系统交互性强速度快 数据更新快

我们也要对业务系统的业务历史数据进行分析  让他进到数仓里面

业务库建模思想是三范式 导入是入库 导出就是ODS进业务库 


-- 列出指定MySQL下的所有的数据库 
sqoop       list-databases  \
--connect  jdbc:mysql://windows:3306  \
--username root \
--password 123456 


-- 列出mysql指定数据库下所有的表 
sqoop       list-tables  \
--connect   jdbc:mysql://windows:3306/doe  \
--username  root \
--password  123456 

-- 将MySQL中的表数据导入到HDFS指定的目录下 
sqoop  import   \
--connect  jdbc:mysql://windows:3306/doe  \
--username root \
--password 123456  \
--table  geo_disct \
--target-dir  /doe/data2/geo_disct/ \
--fields-terminated-by  ,  \  用什么分隔符隔开
-m  1    //指定maptask个数



-- 将表的指定字段导入到HDFS
sqoop  import   \
--connect  jdbc:mysql://windows:3306/doe  \
--username root \
--password root  \
--table  geo_disct \
 --columns  'p , c , r' \     只取表的其中一些字段导入到HDFS
--target-dir  /doe/data2/geo_disct2/ \
--fields-terminated-by  -  \
-m  1 
