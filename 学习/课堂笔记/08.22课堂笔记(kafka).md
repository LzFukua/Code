Kafka
CAP

C 一致性
A 可用性
P 分区容错性

通常这三种特性只能满足两种 会牺牲掉第三种

Kafka为了不让消费者在消费的时候会读出两种结果(因为在读leader的时候有可能会挂掉,从而未同步的broker变成了leader读到的数据不一致)
设置了高水位线 high water mark  让所有消费者只能读到每个broker 偏移量比hw更小的 数据

high water mark代表了数据在多副本间同步的进度
hw就代表offset < hw 的数据已经在所有ISR副本全部备份完毕
也就是所有ISR副本中LEO的最小值



LEO:last and offset 就是记录该副本中消息的 最大偏移量+1
remoteLEO:远程LEO  : 记录follow的LEO


高水位维护理论:
最开始HW会记录最小的remoteLEO 
与此同时,follower发送心跳同步的时候,需要带上自己前一次请求的LEO,leader就会更新remoteLEO
leader返回数据,follower根据自己的offset更新此时的LEO,且更新从Leader返回回来的HW
当所有follower都已经请求过一次同步之后,leader就会更新HW取最小的remoteLEO
当第二次请求时,重复之前的操作


生产者ack选择-1的时候就能避免follower还没同步的时候leader就挂掉所导致的数据丢失,会重试发

致命的问题为,同步了数据但水位线没更新导致的数据截断 就出现了数据丢失现象
为了解决这个问题 引出来纪元的概念

leader-epoch : leader的纪元
每一届leader都要自己的一个纪元号,一个递增的整数
每换届一次,新任leader的纪元号都会在之前的纪元号上增1 
leader-epoch中不光有纪元号,还有这一届leader当选时候的LEO
主要作用: 实现分区副本间数据一致性 


记录的信息本质是:
从哪个offset开始的数据,是哪届leader写入的


于是就有了,当判断的时候,不会从高水位线截断数据,而是去follower去leader上判断纪元,如果纪元相同,则leader发最新的LEO给follower,如果最新的LEO没有超过他本身的LEO,他就不用截断,如果纪元不同(0,0)-->(1,2),leader就会告知follower要将前朝剩余的offset偏移量(原来leader剩余的从2开始往后的数据)给截断,从我这代的偏移量开始记录,然后再去同步数据


(acks=-1) + (leader-epoch)的情况下 数据不会丢失,也不会有数据不一致的问题

kafka通过分区副本机制,以及leader的动态选举机制,提高了整个系统的可用性和分区容错性
但是必然会带来一致性的难题


所以总结为 高水位线HW解决了消费者所见不一致的问题
         leader-epoch解决了副本数据最终一致性的问题





不清洁选举 允许非ISR副本可以选举为leader(有个参数是最近同步请求的时间大于阈值的话,那么就被取消他为ISR副本)

kafka中的幂等性 
同一条数据发送多次,在broker端结果都是一样的: 只存储了一条数据
默认没有开启 开启了会对吞吐量有一定的影响
主要作用: 为了防止生产者失败后的重复写入消息

(in.flight 飞行中的请求 生产者的写出缓存 )


实现原理为:
1. 每一个生产者初始化会生成一个producer_id,并给每个目标分区维护一个"消息序列号"
2. 生产者每发送一条消息,就会将< producer_id,分区 > 的producer_id +1 
3. 然后每发送一条消息都和前一个进行对比
   * 如果 old == new -1  正常 5 = 6-1
   * 如果 old >  new -1  例如 原来存的是6  发过来的是 6号数据 及 6 > 6-1  说明重复写入 直接丢弃数据 
   * 如果 old <  new -1  例如 原来存的是6  发过来的是 7号数据 及 6 < 8-1  说明数据丢失/发生乱序 抛出异常 


kafka事务 
只支持不断追加 所以并不能真正的把未提交的事务结果进行物理回滚 而是让消费者只看到开启事务的那片数据
理论为 从打事务标记的开始到事务结束的标记 让消费者开启只能看到事务提交的数据 这样就能逻辑上展现事务

端到端 一致性的要点
1. 源头端 要能够实现读取位置的记录以及数据的重放
2. 目标端 要能支持事务 或者至少支持 upsert覆盖



