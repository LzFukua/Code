apply 和 process 效果一样 但process 更厉害 可以用到状态
flink的UDF就是用户自己定义的方法函数 


窗口的WaterMark - 进入到每个组内最后一条数据的EventTime > 指定的时间间隔
NonkeyedEvent会话 只要时间不大于水位线,就不会触发
keyedEvent会话  只要时间大于了水位线, 会把整个分区的全部输出

中午最后一节没听

Flink 重启策略 保证Flink容错的重要机制
没有Checkpoint  就没有重启策略
针对于Task
1. 重启次数 
2. 错误率重启策略  也就是在一定时间之内最多可以重启几次
3. 无限重启(开启checkpoint)


什么是状态  是Flink程序运行时产生的中间结果
状态分为两种

1. KeyState  先Keyby再使用后的Stage,数据跟Keyby的key绑定在一起
2. OperatorState 没有Keyby所以没有绑定




----

先keyby然后按照EventTime划分会话窗口 
触发的条件为 窗口的waterMark - 进入到每个组内最后条数据的EventTime > 指定的时间间隔 
就会全部触发  

也就是 1000 的 (flink,spark,hbase 都是1000ms进来的 hive是2000ms进来的 那么 新的某个6001ms来的数据会把堆积在时间间隔内的flink spark hbase全部触发,而hive不会显出来,hive需要等待7001ms的数据  )



新API水位线 (水位线永远只会上增)
会自动帮减水位线的1  就可以0ms的数据  以前4999ms触发窗口  现在5000ms才能出来  但是水位线是4999   

为什么要有窗口 : 希望将数据攒起来做微批次的处理 
时间语义: processTimewindow(按机器时间走) 和 EventTimewindow(按事件时间走,需要设置时间戳或者是日期格式的参数让他知道根据哪个参数作为事件时间)


TumblingProcessingTimeWindows  滚动会话
SlidingProcessingTimeWindows   滑动会话

如果滑动长度和时间长度相同 就是滚动窗口
如果滑动长度小于窗口长度 就是滑动窗口
如果滑动长度大于窗口长度 就会有一部分数据没算 用于数据流的采样 

如何保证下游的窗口以及windowsOperater 对应的多个subtask同时触发呢?
引入了waterMark为了让数据统一处理,且能让数据乱序延迟触发


Flink默认没有设置重启策略 所以一出错程序就关闭
1. fixedDelayRestart 固定次数策略
2. failureRateRestart 在一定时间内 次数超过几次  就会中止程序  
3. checkpointing 从env开启 开启后job就会有重启策略  重启后次数为无限 且有容错机制,会恢复之前的数据(分布式快照)

什么是状态  是Flink程序运行时产生的中间结果
状态分为两种
1. KeyState  先Keyby再使用后的Stage,数据跟Keyby的key绑定在一起 用的最多  (sum reduce 算子都用到了)
2. OperatorState 没有Keyby所以没有绑定

jobmanager内部有一个checkpoint协调器,且内部有个定时器,触发之后向TaskManager中的subtask发送RPC消息,让subtask中持有的状态保存到HDFS中或者别的地方(StateBackEnd 保存状态的存储后端),(存储的文件记录了元信息),然后所有TaskManager返回通知给jobmanager,此次checkpoint才算已经完成,如果中途有个出现异常,jobmanager会将此次checkpoint全部取消

如何实现恢复完数据再读的 : 因为有生命周期方法 一定执行先后顺序

所以Flink容错不仅要开启容错机制,还需要使用Flink的状态编程API 


ValueStateDescriptor<泛型为你要保存的类型>  状态描述器 (描述状态的名称和类型) 
getRuntimeContext().getState(将定义好的状态描述器传入这里)    因为继承了RichXXXFuction 才能调这个方法 才能拿到状态 
相当于一个特殊的HashMap 与我们自己写的Map牛的地方在于能够把数据持久化 默认保存在jobmanager的内存里