主要的工作任务
1. 日志采集 将公司业务系统迈丁的用户行为日志数据通过数据对阶层采集到数据仓库(原始层)
2. 数据预处理 对各种日志行为数据进行预处理 去重 清洗 过滤 集成 session分割
3. 核心工作 
   1. 数仓搭建  数据域的划分 根据不同的数据来源 业务系统的业务域/app端的用户行为域的数据/web端的用户行为域的数据/微信的用户行为域的数据
   2. 报表开发 主题划分 订单主题 用户主题 营销主题(对项目的划分) 4-5个主题 最多10个(完成统计指标的需求)
   3. 数仓分层 ads 数仓报表 对业务服务层  dw数仓核心层  dws服务层 dwd数仓明细层 ods数仓原始层 dim维度
   4. 数据建模 根据业务需求设计出合理的表和计算逻辑
4. 外围的工作 
   1. 任务调度
   2. 质量检测
   3. 元数据管理
   4. 数据看板
5. 意义: 
   1. 使决策层全面了解公司的运行状况
   2. 改善运营效果,提升运营价值,指定运营决策
   3. 为业务系统的某些功能提供技术和数据支撑

session会话 用来统计用户的访问次数以及访问时长


启动flume 命令
bin/flume-ng agent -c conf/ -n a1 -f  props/07last02.conf  -Dflume.root.logger=INFO,console



在flume配置文件中:
没有达到文件滚动的时机,会占用一个临时文件 .tmp , 如果数据长时间没有生成,就会关闭临时文件
a1.sinks.k1.hdfs.idleTimeout = 10s


a1.source.s1.headers.g1.logType = app_log (key)
a1.sinks.k1.hdfs.path = hdfs.//hadoop001:8020/doe/data/%{logType} (value 接收上面传递过来的key) 就可以对文件分区)

将数据sink到HDFS可以获取到数据的头信息  使用当前机器的时间
a1.sinks.k1.hdfs.useLocalTimeStamp = true 
a1.sinks.k1.hdfs.path = hdfs.//hadoop001:8020/doe/data/%{logType}/%Y-%m-%d 


生成的结果文件可以指定文件的前缀和后缀
a1.sinks.k1.hdfs.filePrefix = doit32_ 前缀
a1.sinks.k1.hdfs.fileSuffix = .txt 后缀 一般加的是文件类型


channel 里使用 filechannel 而不是使用 memory 为了保证数据的安全才采用的  但是牺牲了效率
a1.channels.c1.type = flie
启用了checkpoint的机制 双重保证数据的安全
a1.channels.c1.checkpointDir = /opt/flume_data/checkpoint
a1.channels.c1.dataDirs = /opt/flume_data/data 存在哪个文件夹



内置拦截器 
1. 主机拦截器 添加主机名的
a1.sources.r1.interceptors = i1 i2
a1.sources.r1.interceptors = i1.type = host 必须写
a1.sources.r1.interceptors = i1.userIP = false  不使用ID作为主机名
a1.sources.r1.interceptors = i1.hostHeader = hostName 相当于一个变量
a1.sinks.k1.hdfs.path = hdfs.//hadoop001:8020/doe/data/%{logType}/%Y-%m-%d/%{hostName} 传到这里
结果用的还是主机名

2. 静态拦截器
a1.sources.r1.interceptors.i2.type = static 必须写
a1.sources.r1.interceptors.i2.key = author
a1.sources.r1.interceptors.i2.value = chenyang 
a1.sinks.k1.hdfs.path = hdfs.//hadoop001:8020/doe/data/%{logType}/%Y-%m-%d/%{author} 
然后显示的是value chenyang  相当于指定一个值,输出到文件夹去

3. 自定义拦截器(背景 抽取日志中的时间戳,转换成指定的格式,保存路径为事件的时间戳)


