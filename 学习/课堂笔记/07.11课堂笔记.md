Yarn调度策略
1. FIFO 先进先出 一个任务进来时会占据所有的资源,直到任务结束才会释放,所以会造成资源堵塞
2. 容量调度器 像是开启多个FIFO,但如果任务量少就会造成资源的浪费
3. 公平调度器,根据任务的量去分配资源,且会归还资源

##Spark_Yarn_cluster流程
1. 客户端启动SparkSubmit进程
2. 进程向ResoureManager申请Application(申请的时候会带有参数信息需要多大资源)
3. node Manager就会领取任务创建容器
4. 返回applicationid以及可用的资源给予Submit去使用
5. Submit上传程序运行时所需要的各类文件资源
6. submit去设置容器的环境
7. node manager根据客户端的环境要求去下载所需的文件
8. submit就会发送一个启动Applicationmaster进程的shell命令
9.  Applicationmaster就会启动一个Dirver进程用来初始化sparkContext,顺便申请运行executor用的容器
10. 启动executor容器并去Dirver端注册自己
11. Dirver端中TaskScheduler调度器向各个executor发送Task任务

##Spark_Yarn_client流程
与上面不同之处在 8.submit发送的是启动ExecutorLauncher的命令,而ExecutorLauncher只会去申请运行
executor的容器,以及Dirver在submit的机器上生成

##job调度的全流程/RDD的链条是如何编程Task运行起来的?
1. 构建并初始化SparkContext
   1. (主要的有DagScheduler和TaskScheduler,还会创建等待Executor来注册的BackEnd)
2. 创建RDD来构建DAG,触发行动算子,划分阶段,创建TaskSet,生成Task
   1. (生成Task是先生成finalStage,再根据逻辑去判断前面是否有父Stage,一直递归到没有为止才提交job,然后根据分区个数创建Task对象去调用TaskScheduler去提交对象)
3. TaskScheduler就将任务调度以FIFO策略序列化给executor
4. Executor执行Task
   1. (收到Task后反序列化出来,再包装进TaskRunner类放入线程池执行,而线程执行的时候调用的就是Task的runTask方法去将rdd传入ShuffleWriter.write(records)中hasNext/next迭代数据)

Task作用就是拿到rdd的迭代器进行迭代得到数据

---

shuffer有三种方式(都在SortShuffleManager里)
1. BypassMergeSortShufflueHandle
2. SerializedShuffleHandle
3. BaseShuffleHandle

##ShuffleWriter的选取
BypassMergeSortShuffleWriter:Map端不合并且分区数小于200
UnsafeShuffleWriter:必须允许序列化且Map端不合并,reduce数少于2^24
SortShuffle:上面两个都没有选择就选择这个


BaseShuffle的重要部分在,map或者Array所代表的内存数据如果达到阈值了首先是申请更多的内存,直到两个都填满为止才选择溢写
BypassMergeSortShuffle是没有专门的缓存的且不会进行排序,但会把最后的小文件合成大文件(也不会排序)
UnsafeShuffle是对普通Sort的优化,排序的内容是序列化后的字节数组的指针,指针里面前24位记录了PartitionId(也就是分区id)

Spark内存分布
现版本的分了三个大区
1. 统一内存区占了百分之六十,里面分了缓存内存区和执行缓存区
2. 其他区,占了百分之四十,用于定义自定义数据结构或者是存放Spark元数据
3. 预留区,默认为300M用来进行容错性


stage怎么生成的 task怎么生成的


环形缓存区 一个首尾相连的数组 可以使得空间能充分利用    


MR有自己的序列化方式 就是实现Writable接口重写write和readFields方法 out.writeUTF()...
jdk自己的序列化为 new ObjectOutputStream objOut.writeObject(obj); 
Spark也有自己的序列化 调用SparkContext的时候指定使用kryo


###1.为什么scala的迭代器上的map/flatmap...算子，具有lazy执行的特性？
> scala迭代器里的那些算子底层并没有调用HashNext和Next方法,而是根据逻辑创建了一个新的迭代器

##2.迭代器算子中传入的计算函数，要怎样才会真正触发执行？
> 需要有像foreach这样的行动算子才会真的触发执行(本质上就是要调用迭代器的hasNext和next方法)

##3.为什么rdd的transformation算子，具有lazy执行的特性？
> 因为RDD的转换算子底层没有触发阶段划分,job提交或者task提交的动作,而只是根据逻辑创健了一个新的RDD实例返回,所以并没有触发任务的执行

##4.为什么调用rdd的action算子，就能触发计算逻辑的执行？
> 因为行动算子中都会有一个runjob方法调用DAGscheduler进行stage的划分生成TaskSet,再用TaskScheduler去分配任务给各个Executor去执行自己每个Task分区的任务

##5.为什么说rdd中并没有真正存储数据？而触发rdd上的行动算子时又能拿到计算结果是为什么？
> 因为RDD存储的是里面的compute方法套了前一个rdd的转换逻辑,而行动算子触发了runjob,会追溯到初代RDD获取数据的位置再根据计算逻辑处理数据得到结果


