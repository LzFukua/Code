spark sql 底层转换原理

第一步 解析sql语句
第二步 绑定元数据
第三步 优化sql语句
第四步 生成执行代码

1. 使用parser解析器去解析sql语句 生成逻辑执行计划
2. analyzer绑定catalog元数据信息 生成绑定了元数据信息的逻辑执行计划
3. optimizer优化sql执行逻辑
4. planer生成物理执行计划
5. execution转成RDD 

逻辑执行计划和物理执行计划的区别最大的在于是否绑定了元数据信息

B-S 网络要求高 类似于网页浏览 客户端更新了本地不用更新
C-S 内存要求高 例如游戏  客户端要更新,所有人都需要更新


sql 进来用parser先生成一个AST语法树 spark逻辑执行计划 
analyzer的exectuteAndCheck 

总结
1. sql进来会传入sqlparser 生成未绑定的逻辑执行计划的
2. 接着传入到Analyzer去绑定元数据信息catalog,得到绑定了元数据信息的逻辑执行计划,根据计划生成了一个DataSet返回
3. 再传入到optimizer中去优化
4. 最后放到planner里生成物理执行计划
5. 里面的execute触发了getByteArrayRDD,生成 doCodeGen 和 inputRDDS
6. doCodeGen对代码进行编译,反射,实例化,生成了一个包含stage的计算逻辑的迭代器,而inputRDDS用mappartitionswithindex将迭代器传入里面得到一个RDD